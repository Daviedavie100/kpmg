{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from datetime import datetime as dt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PowerTransformer\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file path\n",
    "file_path=\"C:/Users/Davie/Desktop/introduction-to-power-bi/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load demographic data\n",
    "demographic=pd.read_excel(file_path+\"KPMG/KPMG_VI_New_raw_data_update_final.xlsx\",sheet_name='CustomerDemographic', index_col=False, header=0, usecols=\"A:M\", skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load customer address\n",
    "address=pd.read_excel(file_path+\"KPMG/KPMG_VI_New_raw_data_update_final.xlsx\",sheet_name='CustomerAddress', index_col=False, header=0, usecols=\"A:F\", skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load transaction data\n",
    "transactions=pd.read_excel(file_path+\"KPMG/KPMG_VI_New_raw_data_update_final.xlsx\",sheet_name='Transactions', index_col=False, header=0, usecols=\"A:M\", skiprows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge demographic data with customer address\n",
    "demographic_address=pd.merge(demographic, address, on='customer_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged all the 3 datasets\n",
    "demographic_address_transactions=pd.merge(demographic_address, transactions, on='customer_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicates and ulls\n",
    "df=demographic_address_transactions.drop_duplicates().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make copy of the data\n",
    "data=df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate profit margin\n",
    "data['profit_margin']=data['list_price']-data['standard_cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate product margin\n",
    "data['product_margin']=(data['list_price']-data['standard_cost'])/data['list_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate age\n",
    "\n",
    "# convert DOB to datetime\n",
    "data['DOB']=pd.to_datetime(data['DOB'])\n",
    "# Get the current date\n",
    "current_date = pd.to_datetime('today')\n",
    "# Calculate age using apply and a lambda function to handle the year difference\n",
    "data['age'] = df['DOB'].apply(lambda x: current_date.year - x.year - ((current_date.month, current_date.day) < (x.month, x.day)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define age bins and labels\n",
    "bins = [0, 25, 35, 45, 55, 65, 100]\n",
    "labels = ['0-25','25-35', '35-45', '45-55', '55-65', 'Above 65']\n",
    "\n",
    "# Create age groups\n",
    "data['age_group'] = pd.cut(data['age'], bins=bins, labels=labels, right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date of transaction\n",
    "data['transaction_date'] = pd.to_datetime(data['transaction_date'])\n",
    "\n",
    "# Extract the daya, monthand year from transaction_date\n",
    "data['trans_day'] = data['transaction_date'].dt.day\n",
    "data['trans_month'] = data['transaction_date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace values for gender and state in the entire DataFrame\n",
    "data['gender'] = data['gender'].replace({'Femal': 'Female', 'F': 'Female'})\n",
    "data['state']=data['state'].replace({'New South Wales':'NSW','Victoria':'VIC'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution for Bikes Purchased to be used as the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Frequency'>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#histogram\n",
    "data['past_3_years_bike_related_purchases'].plot.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#box plot\n",
    "data['past_3_years_bike_related_purchases'].plot.box()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['customer_id', 'first_name', 'last_name', 'gender',\n",
       "       'past_3_years_bike_related_purchases', 'DOB', 'job_title',\n",
       "       'job_industry_category', 'wealth_segment', 'deceased_indicator',\n",
       "       'default', 'owns_car', 'tenure', 'address', 'postcode', 'state',\n",
       "       'country', 'property_valuation', 'transaction_id', 'product_id',\n",
       "       'transaction_date', 'online_order', 'order_status', 'brand',\n",
       "       'product_line', 'product_class', 'product_size', 'list_price',\n",
       "       'standard_cost', 'product_first_sold_date', 'profit_margin',\n",
       "       'product_margin', 'age', 'age_group', 'trans_day', 'trans_month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking new columns\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select columns to use in the Model\n",
    "cols=['gender', 'age', 'age_group', 'trans_month', 'trans_day', 'state', 'job_industry_category' ,'job_title', 'online_order', 'order_status' ,'wealth_segment',  'brand','product_line', 'product_class', 'product_size', 'tenure', 'past_3_years_bike_related_purchases', 'profit_margin', 'product_margin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select model columns\n",
    "data=data[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop nulls\n",
    "data_clean=data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding\n",
    "- Choose the encoding method based on the nature of your data and the requirements of your machine learning model. \n",
    "- `One-hot encoding` is suitable when there is no ordinal relationship between categories\n",
    "- `label encoding` is useful when there is an ordinal relationship between categories. \n",
    "- **Example**\n",
    "    - Label encoding for Ordinal Variables\n",
    "    - `ordinal_mapping_prod_size = {'small': 0, 'medium': 1, 'large': 2} #product size`\n",
    "    - `ordinal_data['product_size'] = ordinal_data['product_size'].map(ordinal_mapping_prod_size)`\n",
    "    - `data.reset_index(drop=True, inplace=True)`  # Reset index of X without adding it as a new column\n",
    "- Always remember to handle unknown categories appropriately, especially when using one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating binary variable from continous variable\n",
    "\n",
    "#create threshold\n",
    "threshold=data['past_3_years_bike_related_purchases'].median()\n",
    "# create high buyers and low buyers\n",
    "data_clean['bikes_purchased']=(data_clean['past_3_years_bike_related_purchases']>threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>age_group</th>\n",
       "      <th>trans_month</th>\n",
       "      <th>trans_day</th>\n",
       "      <th>state</th>\n",
       "      <th>job_industry_category</th>\n",
       "      <th>job_title</th>\n",
       "      <th>online_order</th>\n",
       "      <th>order_status</th>\n",
       "      <th>wealth_segment</th>\n",
       "      <th>brand</th>\n",
       "      <th>product_line</th>\n",
       "      <th>product_class</th>\n",
       "      <th>product_size</th>\n",
       "      <th>tenure</th>\n",
       "      <th>past_3_years_bike_related_purchases</th>\n",
       "      <th>profit_margin</th>\n",
       "      <th>product_margin</th>\n",
       "      <th>bikes_purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>93</td>\n",
       "      <td>110.56</td>\n",
       "      <td>0.469210</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>71</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>93</td>\n",
       "      <td>751.02</td>\n",
       "      <td>0.476073</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>71</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11.0</td>\n",
       "      <td>93</td>\n",
       "      <td>189.28</td>\n",
       "      <td>0.110002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>93</td>\n",
       "      <td>90.10</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>93</td>\n",
       "      <td>17.87</td>\n",
       "      <td>0.249965</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  age  age_group  trans_month  trans_day  state  \\\n",
       "0       0   70          5           12         23      0   \n",
       "1       0   70          5            4          6      0   \n",
       "2       0   70          5            5         11      0   \n",
       "3       0   70          5            1          5      0   \n",
       "4       0   70          5            2         21      0   \n",
       "\n",
       "   job_industry_category  job_title  online_order  order_status  \\\n",
       "0                      3         71           0.0             0   \n",
       "1                      3         71           1.0             0   \n",
       "2                      3         71           1.0             0   \n",
       "3                      3         71           0.0             0   \n",
       "4                      3         71           0.0             0   \n",
       "\n",
       "   wealth_segment  brand  product_line  product_class  product_size  tenure  \\\n",
       "0               2      2             2              2             1    11.0   \n",
       "1               2      3             2              2             1    11.0   \n",
       "2               2      4             1              1             2    11.0   \n",
       "3               2      1             2              2             1    11.0   \n",
       "4               2      3             2              2             1    11.0   \n",
       "\n",
       "   past_3_years_bike_related_purchases  profit_margin  product_margin  \\\n",
       "0                                   93         110.56        0.469210   \n",
       "1                                   93         751.02        0.476073   \n",
       "2                                   93         189.28        0.110002   \n",
       "3                                   93          90.10        0.250000   \n",
       "4                                   93          17.87        0.249965   \n",
       "\n",
       "   bikes_purchased  \n",
       "0                1  \n",
       "1                1  \n",
       "2                1  \n",
       "3                1  \n",
       "4                1  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select categorical columns\n",
    "categorical_cols = ['gender', 'age_group', 'state', 'job_industry_category', 'job_title', \n",
    "                    'order_status', 'wealth_segment', 'brand', 'product_line', 'product_class', 'product_size']\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Apply Label Encoding to each column\n",
    "for col in categorical_cols:\n",
    "    data_clean[col] = label_encoder.fit_transform(data_clean[col])\n",
    "\n",
    "# Display the updated DataFrame\n",
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_encoded=['age', 'trans_day', 'trans_month', 'product_margin','bikes_purchased','trans_day', 'profit_margin', \n",
    "              'product_size', 'product_class', 'gender', 'age_group', 'state', 'job_industry_category' ,'job_title', \n",
    "              'online_order', 'order_status','wealth_segment', \n",
    "              'brand', 'product_line']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make copy\n",
    "model_data=data_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# For simplicity, let\\'s assume we rename duplicated columns by appending \"_dup\"\\ncols = pd.Series(model_data.columns)\\nfor dup in cols[cols.duplicated()].unique():\\n    cols[cols[cols == dup].index.values.tolist()] = [dup + \\'_dup\\' if i != 0 else dup for i in range(sum(cols == dup))]\\n\\n# Assign the new columns back to the dataframe\\nmodel_data.columns = cols'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# For simplicity, let's assume we rename duplicated columns by appending \"_dup\"\n",
    "cols = pd.Series(model_data.columns)\n",
    "for dup in cols[cols.duplicated()].unique():\n",
    "    cols[cols[cols == dup].index.values.tolist()] = [dup + '_dup' if i != 0 else dup for i in range(sum(cols == dup))]\n",
    "\n",
    "# Assign the new columns back to the dataframe\n",
    "model_data.columns = cols'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant features and the target variable\n",
    "X = model_data.drop(columns=['bikes_purchased'])\n",
    "y = model_data['bikes_purchased']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical and numerical columns\n",
    "categorical_features = ['gender', 'age_group', 'state', 'job_industry_category', 'job_title', \n",
    "                        'order_status', 'wealth_segment', 'brand', 'product_line', 'product_class', 'product_size']\n",
    "numerical_features = ['age', 'product_margin', 'profit_margin', 'trans_day', 'trans_month']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM FOREST CLASSIFICATION\n",
    "- NO imbalance in the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.06914814957594449\n",
      "R^2 Score: 0.7232874859052738\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[121], line 41\u001b[0m\n\u001b[0;32m     34\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregressor__n_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m],\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregressor__max_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m30\u001b[39m],\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregressor__min_samples_split\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m10\u001b[39m]\n\u001b[0;32m     38\u001b[0m }\n\u001b[0;32m     40\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(model, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 41\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Best parameters and score\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest parameters:\u001b[39m\u001b[38;5;124m'\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[1;32mc:\\Anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1418\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1419\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Anaconda3\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Anaconda3\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:732\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    730\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    731\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 732\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    736\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:420\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    419\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m--> 420\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_last_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    445\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    448\u001b[0m ]\n\u001b[0;32m    450\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 456\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Anaconda3\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Anaconda3\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:188\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    186\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 188\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:1320\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1292\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m \n\u001b[0;32m   1294\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1317\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1318\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1320\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1322\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    434\u001b[0m         splitter,\n\u001b[0;32m    435\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    441\u001b[0m     )\n\u001b[1;32m--> 443\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Preprocessing pipeline for numerical data\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "# Preprocessing pipeline for categorical data\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create a pipeline with RandomForestRegressor\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f'Mean Squared Error: {mean_squared_error(y_test, y_pred)}')\n",
    "print(f'R^2 Score: {r2_score(y_test, y_pred)}')\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [50, 100, 200],\n",
    "    'regressor__max_depth': [None, 10, 20, 30],\n",
    "    'regressor__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print('Best parameters:', grid_search.best_params_)\n",
    "print('Best Mean Squared Error:', -grid_search.best_score_)  # Convert back to positive MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LINEAR RGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.23420578427098657\n",
      "R^2 Score: 0.06277070639505178\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing pipeline for numerical data\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "# Preprocessing pipeline for categorical data\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create a pipeline with LinearRegression\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f'Mean Squared Error: {mean_squared_error(y_test, y_pred)}')\n",
    "print(f'R^2 Score: {r2_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DECISSION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing pipeline for numerical data\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "# Preprocessing pipeline for categorical data\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create a pipeline with DecisionTreeRegressor\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', DecisionTreeRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f'Mean Squared Error: {mean_squared_error(y_test, y_pred)}')\n",
    "print(f'R^2 Score: {r2_score(y_test, y_pred)}')\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'regressor__max_depth': [None, 10, 20, 30],\n",
    "    'regressor__min_samples_split': [2, 5, 10],\n",
    "    'regressor__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print('Best parameters:', grid_search.best_params_)\n",
    "print('Best Mean Squared Error:', -grid_search.best_score_)  # Convert back to positive MSE\n",
    "\n",
    "# Use the best estimator for predictions\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Final evaluation of the tuned model\n",
    "print(f'Mean Squared Error (tuned): {mean_squared_error(y_test, y_pred)}')\n",
    "print(f'R^2 Score (tuned): {r2_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: Based on age group, gender, and state, what are the key target demographics for bike purchases?\n",
    "\n",
    "#### Q2: Predictive Modeling:\n",
    "- Can you build a model to predict the likelihood of bike purchases based on demographic and product characteristics?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOGISTIC REGRESSION\n",
    "- Logistic regression is used for classification tasks, not regression. Since you want to predict the likelihood of bike purchases, which is a binary classification problem, logistic regression is indeed appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Convert the target variable to binary if it isn't already\n",
    "y = y.apply(lambda x: 1 if x >0 else 0)  # Assuming bike_purchases &gt; 0 means a purchase\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "'''categorical_features = ['gender', 'age_group', 'state', 'job_industry_category', 'job_title', \n",
    "                        'order_status', 'wealth_segment', 'brand', 'product_line', 'online_order']\n",
    "numerical_features = ['age', 'product_margin', 'profit_margin', 'trans_day', 'trans_month']'''\n",
    "\n",
    "# Preprocessing pipeline for numerical data\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "# Preprocessing pipeline for categorical data\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create a pipeline with LogisticRegression\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "print(f'Precision: {precision_score(y_test, y_pred)}')\n",
    "print(f'Recall: {recall_score(y_test, y_pred)}')\n",
    "print(f'F1 Score: {f1_score(y_test, y_pred)}')\n",
    "print(f'ROC AUC Score: {roc_auc_score(y_test, y_pred)}')\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'classifier__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'classifier__penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'classifier__solver': ['lbfgs', 'liblinear', 'saga']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='roc_auc')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print('Best parameters:', grid_search.best_params_)\n",
    "print('Best ROC AUC Score:', grid_search.best_score_)\n",
    "\n",
    "# Use the best estimator for predictions\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Final evaluation of the tuned model\n",
    "print(f'Accuracy (tuned): {accuracy_score(y_test, y_pred)}')\n",
    "print(f'Precision (tuned): {precision_score(y_test, y_pred)}')\n",
    "print(f'Recall (tuned): {recall_score(y_test, y_pred)}')\n",
    "print(f'F1 Score (tuned): {f1_score(y_test, y_pred)}')\n",
    "print(f'ROC AUC Score (tuned): {roc_auc_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpreting the LOGISTIC CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpret the model coefficients\n",
    "# Get the feature names after one-hot encoding and scaling\n",
    "onehot_columns = model.named_steps['preprocessor'].transformers_[1][1].get_feature_names_out(categorical_features)\n",
    "all_feature_names = np.hstack([numerical_features, onehot_columns])\n",
    "\n",
    "# Get the coefficients from the logistic regression model\n",
    "coefficients = model.named_steps['classifier'].coef_[0]\n",
    "\n",
    "# Create a DataFrame for the coefficients\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': all_feature_names,\n",
    "    'Coefficient': coefficients\n",
    "})\n",
    "\n",
    "# Sort by absolute value of the coefficient to see the most influential features\n",
    "coef_df['Absolute Coefficient'] = coef_df['Coefficient'].abs()\n",
    "coef_df = coef_df.sort_values(by='Absolute Coefficient', ascending=False)\n",
    "\n",
    "print(coef_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter coefficients for negative contribution to bike purchases\n",
    "negative_coef_df = coef_df[coef_df['Coefficient'] < 0]\n",
    "\n",
    "# Sort coefficients in ascending order (from most negative to least negative)\n",
    "negative_coef_df = negative_coef_df.sort_values(by='Coefficient', ascending=True)\n",
    "\n",
    "# Plot the coefficients for negative contribution to bike purchases\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(negative_coef_df['Feature'], negative_coef_df['Coefficient'], color='salmon')\n",
    "plt.xlabel('Coefficient')\n",
    "plt.title('Logistic Regression Coefficients for Negative Contribution to Bike Purchases (Most Negative to Least Negative)')\n",
    "plt.grid(axis='x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter coefficients for negative contribution to bike purchases\n",
    "negative_coef_df = coef_df[coef_df['Coefficient'] < 0]\n",
    "\n",
    "# Group coefficients by feature category\n",
    "grouped_negative_coef_df = negative_coef_df.groupby('Feature').sum().reset_index()\n",
    "\n",
    "# Sort coefficients in ascending order (from most negative to least negative)\n",
    "grouped_negative_coef_df = grouped_negative_coef_df.sort_values(by='Coefficient', ascending=True)\n",
    "\n",
    "# Plot the summarized coefficients for negative contribution to bike purchases\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(grouped_negative_coef_df['Feature'], grouped_negative_coef_df['Coefficient'], color='salmon')\n",
    "plt.xlabel('Coefficient')\n",
    "plt.title('Summarized Logistic Regression Coefficients for Negative Contribution to Bike Purchases')\n",
    "plt.grid(axis='x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter coefficients for positive influence\n",
    "positive_coef_df = coef_df[coef_df['Coefficient'] > 0]\n",
    "\n",
    "# Sort coefficients in descending order\n",
    "positive_coef_df = positive_coef_df.sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "# Plot the coefficients for positive influence\n",
    "plt.figure(figsize=(10, 40))\n",
    "plt.barh(positive_coef_df['Feature'], positive_coef_df['Coefficient'], color='skyblue')\n",
    "plt.xlabel('Coefficient')\n",
    "plt.title('Logistic Regression Coefficients for Positive Influence')\n",
    "plt.grid(axis='x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use RandomForestRegressor when your target variable is a continuous value that you need to predict.\n",
    "- Use RandomForestClassifier when your target variable is a categorical label or class."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uscholar_py3.6_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
