{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from datetime import datetime as dt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PowerTransformer\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file path\n",
    "file_path=\"C:/Users/Davie/Desktop/introduction-to-power-bi/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load demographic data\n",
    "demographic=pd.read_excel(file_path+\"KPMG/KPMG_VI_New_raw_data_update_final.xlsx\",sheet_name='CustomerDemographic', index_col=False, header=0, usecols=\"A:M\", skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load customer address\n",
    "address=pd.read_excel(file_path+\"KPMG/KPMG_VI_New_raw_data_update_final.xlsx\",sheet_name='CustomerAddress', index_col=False, header=0, usecols=\"A:F\", skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load transaction data\n",
    "transactions=pd.read_excel(file_path+\"KPMG/KPMG_VI_New_raw_data_update_final.xlsx\",sheet_name='Transactions', index_col=False, header=0, usecols=\"A:M\", skiprows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge demographic data with customer address\n",
    "demographic_address=pd.merge(demographic, address, on='customer_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged all the 3 datasets\n",
    "demographic_address_transactions=pd.merge(demographic_address, transactions, on='customer_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicates and ulls\n",
    "df=demographic_address_transactions.drop_duplicates().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make copy of the data\n",
    "data=df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate profit margin\n",
    "data['profit_margin']=data['list_price']-data['standard_cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate product margin\n",
    "data['product_margin']=(data['list_price']-data['standard_cost'])/data['list_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate age\n",
    "\n",
    "# convert DOB to datetime\n",
    "data['DOB']=pd.to_datetime(data['DOB'])\n",
    "# Get the current date\n",
    "current_date = pd.to_datetime('today')\n",
    "# Calculate age using apply and a lambda function to handle the year difference\n",
    "data['age'] = df['DOB'].apply(lambda x: current_date.year - x.year - ((current_date.month, current_date.day) < (x.month, x.day)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define age bins and labels\n",
    "bins = [0, 25, 35, 45, 55, 65, 100]\n",
    "labels = ['0-25','25-35', '35-45', '45-55', '55-65', 'Above 65']\n",
    "\n",
    "# Create age groups\n",
    "data['age_group'] = pd.cut(data['age'], bins=bins, labels=labels, right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date of transaction\n",
    "data['transaction_date'] = pd.to_datetime(data['transaction_date'])\n",
    "\n",
    "# Extract the daya, monthand year from transaction_date\n",
    "data['trans_day'] = data['transaction_date'].dt.day\n",
    "\n",
    "data['trans_month'] = data['transaction_date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace values in the entire DataFrame\n",
    "data['gender'] = data['gender'].replace({'Femal': 'Female', 'F': 'Female'})\n",
    "data['state']=data['state'].replace({'New South Wales':'NSW','Victoria':'VIC'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Frequency'>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['past_3_years_bike_related_purchases'].plot.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=data['past_3_years_bike_related_purchases'].median()\n",
    "#data['bikes_purchased']=data['past_3_years_bike_related_purchases']>threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        True\n",
       "1        True\n",
       "2        True\n",
       "3        True\n",
       "4        True\n",
       "         ... \n",
       "19944    True\n",
       "19945    True\n",
       "19946    True\n",
       "19947    True\n",
       "19948    True\n",
       "Name: past_3_years_bike_related_purchases, Length: 12970, dtype: bool"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['past_3_years_bike_related_purchases']>threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['past_3_years_bike_related_purchases'].plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['gender', 'age', 'age_group', 'trans_month', 'trans_day', 'state', 'job_industry_category' ,'job_title', 'online_order', 'order_status' ,'wealth_segment',  'brand','product_line', 'product_class', 'product_size', 'tenure', 'past_3_years_bike_related_purchases', 'profit_margin', 'product_margin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={'past_3_years_bike_related_purchases':'bike_purchases'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean=data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Choose the encoding method based on the nature of your data and the requirements of your machine learning model. \n",
    "- One-hot encoding is suitable when there is no ordinal relationship between categories, while label encoding can be useful when there is an ordinal relationship between categories. \n",
    "- Always remember to handle unknown categories appropriately, especially when using one-hot encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "- Select categorical columns\n",
    "categorical_cols = ['gender', 'age_group', 'state', 'job_industry_category', 'job_title', \n",
    "                    'order_status', 'wealth_segment', 'brand', 'product_line']\n",
    "\n",
    "- Initialize OneHotEncoder\n",
    "one_hot_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "- Apply One-Hot Encoding to selected columns and convert to DataFrame\n",
    "one_hot_encoded = pd.DataFrame(one_hot_encoder.fit_transform(data[categorical_cols]))\n",
    "\n",
    "- Rename one-hot encoded columns\n",
    "one_hot_encoded.columns = one_hot_encoder.get_feature_names(categorical_cols)\n",
    "\n",
    "- Replace original categorical columns with one-hot encoded columns\n",
    "data = data.drop(categorical_cols, axis=1)\n",
    "data = pd.concat([data, one_hot_encoded], axis=1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select categorical columns\n",
    "categorical_cols = ['gender', 'age_group', 'state', 'job_industry_category', 'job_title', \n",
    "                    'order_status', 'wealth_segment', 'brand', 'product_line', 'product_class', 'product_size']\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Apply Label Encoding to each column\n",
    "for col in categorical_cols:\n",
    "    data_clean[col] = label_encoder.fit_transform(data_clean[col])\n",
    "\n",
    "# Display the updated DataFrame\n",
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Label encoding for Ordinal Variables\n",
    "\n",
    "- `ordinal_mapping_prod_size = {'small': 0, 'medium': 1, 'large': 2} #product size`\n",
    "- `ordinal_data['product_size'] = ordinal_data['product_size'].map(ordinal_mapping_prod_size)`\n",
    "- `data.reset_index(drop=True, inplace=True)`  # Reset index of X without adding it as a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_encoded=['age', 'trans_day', 'trans_month', 'product_margin','bike_purchases','trans_day', 'profit_margin', \n",
    "              'product_size', 'product_class', 'gender', 'age_group',  'state', 'job_industry_category' ,'job_title', \n",
    "              'online_order', 'order_status','wealth_segment', \n",
    "              'brand', 'product_line'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data=data_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For simplicity, let's assume we rename duplicated columns by appending \"_dup\"\n",
    "cols = pd.Series(model_data.columns)\n",
    "for dup in cols[cols.duplicated()].unique():\n",
    "    cols[cols[cols == dup].index.values.tolist()] = [dup + '_dup' if i != 0 else dup for i in range(sum(cols == dup))]\n",
    "\n",
    "# Assign the new columns back to the dataframe\n",
    "model_data.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant features and the target variable\n",
    "#X = data_encoded[[i for i in data_encoded.columns if i !='bike_purchases']]\n",
    "\n",
    "X = model_data.drop(columns=['bike_purchases'])\n",
    "y = model_data['bike_purchases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical and numerical columns\n",
    "categorical_features = ['gender', 'age_group', 'state', 'job_industry_category', 'job_title', \n",
    "                        'order_status', 'wealth_segment', 'brand', 'product_line', 'product_class', 'product_size']\n",
    "numerical_features = ['age', 'product_margin', 'profit_margin', 'trans_day', 'trans_month']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HANDLING IMBALANCE IN REGRESSION (RANDOM FOREST REGRESSION)\n",
    "- Handling imbalance in the target variable is more critical in classification problems than in regression problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing pipeline for numerical data\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('power_transform', PowerTransformer(method='yeo-johnson'))\n",
    "])\n",
    "\n",
    "# Preprocessing pipeline for categorical data\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create a pipeline with RandomForestRegressor\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Transform the target variable\n",
    "power_transformer = PowerTransformer(method='yeo-johnson')\n",
    "y_train_transformed = power_transformer.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_test_transformed = power_transformer.transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train_transformed)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_transformed = model.predict(X_test)\n",
    "\n",
    "# Inverse transform the predictions\n",
    "y_pred = power_transformer.inverse_transform(y_pred_transformed.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Evaluate the model\n",
    "print(f'Mean Squared Error: {mean_squared_error(y_test, y_pred)}')\n",
    "print(f'R^2 Score: {r2_score(y_test, y_pred)}')\n",
    "\n",
    "'''# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [50, 100, 200],\n",
    "    'regressor__max_depth': [None, 10, 20, 30],\n",
    "    'regressor__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train_transformed)\n",
    "\n",
    "# Best parameters and score\n",
    "print('Best parameters:', grid_search.best_params_)\n",
    "print('Best Mean Squared Error:', -grid_search.best_score_)  # Convert back to positive MSE'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NO IMBALANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing pipeline for numerical data\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "# Preprocessing pipeline for categorical data\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create a pipeline with RandomForestRegressor\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f'Mean Squared Error: {mean_squared_error(y_test, y_pred)}')\n",
    "print(f'R^2 Score: {r2_score(y_test, y_pred)}')\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [50, 100, 200],\n",
    "    'regressor__max_depth': [None, 10, 20, 30],\n",
    "    'regressor__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print('Best parameters:', grid_search.best_params_)\n",
    "print('Best Mean Squared Error:', -grid_search.best_score_)  # Convert back to positive MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMBALANCE IN LINEAR RGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing pipeline for numerical data\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Preprocessing pipeline for categorical data\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create a pipeline with LinearRegression\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Optionally, transform the target variable if needed\n",
    "power_transformer = PowerTransformer(method='yeo-johnson')\n",
    "y_train_transformed = power_transformer.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_test_transformed = power_transformer.transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train_transformed)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_transformed = model.predict(X_test)\n",
    "\n",
    "# Inverse transform the predictions\n",
    "y_pred = power_transformer.inverse_transform(y_pred_transformed.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Evaluate the model\n",
    "print(f'Mean Squared Error: {mean_squared_error(y_test, y_pred)}')\n",
    "print(f'R^2 Score: {r2_score(y_test, y_pred)}')\n",
    "\n",
    "'''# Hyperparameter tuning (if applicable to Linear Regression)\n",
    "# LinearRegression itself doesn't have hyperparameters to tune, but you can use regularization methods\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Create a pipeline with Ridge regression\n",
    "model_ridge = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', Ridge())\n",
    "])\n",
    "\n",
    "# Define parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'regressor__alpha': [0.1, 1.0, 10.0, 100.0]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model_ridge, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train_transformed)\n",
    "\n",
    "# Best parameters and score\n",
    "print('Best parameters:', grid_search.best_params_)\n",
    "print('Best Mean Squared Error:', -grid_search.best_score_)  # Convert back to positive MSE\n",
    "\n",
    "# Use the best estimator for predictions\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_transformed = best_model.predict(X_test)\n",
    "y_pred = power_transformer.inverse_transform(y_pred_transformed.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Final evaluation of the tuned model\n",
    "print(f'Mean Squared Error (tuned): {mean_squared_error(y_test, y_pred)}')\n",
    "print(f'R^2 Score (tuned): {r2_score(y_test, y_pred)}')'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NO IMBALANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing pipeline for numerical data\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "# Preprocessing pipeline for categorical data\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create a pipeline with LinearRegression\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f'Mean Squared Error: {mean_squared_error(y_test, y_pred)}')\n",
    "print(f'R^2 Score: {r2_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECISSION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing pipeline for numerical data\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "# Preprocessing pipeline for categorical data\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create a pipeline with DecisionTreeRegressor\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', DecisionTreeRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f'Mean Squared Error: {mean_squared_error(y_test, y_pred)}')\n",
    "print(f'R^2 Score: {r2_score(y_test, y_pred)}')\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'regressor__max_depth': [None, 10, 20, 30],\n",
    "    'regressor__min_samples_split': [2, 5, 10],\n",
    "    'regressor__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print('Best parameters:', grid_search.best_params_)\n",
    "print('Best Mean Squared Error:', -grid_search.best_score_)  # Convert back to positive MSE\n",
    "\n",
    "# Use the best estimator for predictions\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Final evaluation of the tuned model\n",
    "print(f'Mean Squared Error (tuned): {mean_squared_error(y_test, y_pred)}')\n",
    "print(f'R^2 Score (tuned): {r2_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: Based on age group, gender, and state, what are the key target demographics for bike purchases?\n",
    "\n",
    "#### Q2: Predictive Modeling:\n",
    "- Can you build a model to predict the likelihood of bike purchases based on demographic and product characteristics?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION\n",
    "- Logistic regression is used for classification tasks, not regression. Since you want to predict the likelihood of bike purchases, which is a binary classification problem, logistic regression is indeed appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Convert the target variable to binary if it isn't already\n",
    "y = y.apply(lambda x: 1 if x >0 else 0)  # Assuming bike_purchases &gt; 0 means a purchase\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "'''categorical_features = ['gender', 'age_group', 'state', 'job_industry_category', 'job_title', \n",
    "                        'order_status', 'wealth_segment', 'brand', 'product_line', 'online_order']\n",
    "numerical_features = ['age', 'product_margin', 'profit_margin', 'trans_day', 'trans_month']'''\n",
    "\n",
    "# Preprocessing pipeline for numerical data\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "# Preprocessing pipeline for categorical data\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create a pipeline with LogisticRegression\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "print(f'Precision: {precision_score(y_test, y_pred)}')\n",
    "print(f'Recall: {recall_score(y_test, y_pred)}')\n",
    "print(f'F1 Score: {f1_score(y_test, y_pred)}')\n",
    "print(f'ROC AUC Score: {roc_auc_score(y_test, y_pred)}')\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'classifier__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'classifier__penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'classifier__solver': ['lbfgs', 'liblinear', 'saga']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='roc_auc')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print('Best parameters:', grid_search.best_params_)\n",
    "print('Best ROC AUC Score:', grid_search.best_score_)\n",
    "\n",
    "# Use the best estimator for predictions\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Final evaluation of the tuned model\n",
    "print(f'Accuracy (tuned): {accuracy_score(y_test, y_pred)}')\n",
    "print(f'Precision (tuned): {precision_score(y_test, y_pred)}')\n",
    "print(f'Recall (tuned): {recall_score(y_test, y_pred)}')\n",
    "print(f'F1 Score (tuned): {f1_score(y_test, y_pred)}')\n",
    "print(f'ROC AUC Score (tuned): {roc_auc_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpreting the LOGISTIC CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpret the model coefficients\n",
    "# Get the feature names after one-hot encoding and scaling\n",
    "onehot_columns = model.named_steps['preprocessor'].transformers_[1][1].get_feature_names_out(categorical_features)\n",
    "all_feature_names = np.hstack([numerical_features, onehot_columns])\n",
    "\n",
    "# Get the coefficients from the logistic regression model\n",
    "coefficients = model.named_steps['classifier'].coef_[0]\n",
    "\n",
    "# Create a DataFrame for the coefficients\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': all_feature_names,\n",
    "    'Coefficient': coefficients\n",
    "})\n",
    "\n",
    "# Sort by absolute value of the coefficient to see the most influential features\n",
    "coef_df['Absolute Coefficient'] = coef_df['Coefficient'].abs()\n",
    "coef_df = coef_df.sort_values(by='Absolute Coefficient', ascending=False)\n",
    "\n",
    "print(coef_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter coefficients for negative contribution to bike purchases\n",
    "negative_coef_df = coef_df[coef_df['Coefficient'] < 0]\n",
    "\n",
    "# Sort coefficients in ascending order (from most negative to least negative)\n",
    "negative_coef_df = negative_coef_df.sort_values(by='Coefficient', ascending=True)\n",
    "\n",
    "# Plot the coefficients for negative contribution to bike purchases\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(negative_coef_df['Feature'], negative_coef_df['Coefficient'], color='salmon')\n",
    "plt.xlabel('Coefficient')\n",
    "plt.title('Logistic Regression Coefficients for Negative Contribution to Bike Purchases (Most Negative to Least Negative)')\n",
    "plt.grid(axis='x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter coefficients for negative contribution to bike purchases\n",
    "negative_coef_df = coef_df[coef_df['Coefficient'] < 0]\n",
    "\n",
    "# Group coefficients by feature category\n",
    "grouped_negative_coef_df = negative_coef_df.groupby('Feature').sum().reset_index()\n",
    "\n",
    "# Sort coefficients in ascending order (from most negative to least negative)\n",
    "grouped_negative_coef_df = grouped_negative_coef_df.sort_values(by='Coefficient', ascending=True)\n",
    "\n",
    "# Plot the summarized coefficients for negative contribution to bike purchases\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(grouped_negative_coef_df['Feature'], grouped_negative_coef_df['Coefficient'], color='salmon')\n",
    "plt.xlabel('Coefficient')\n",
    "plt.title('Summarized Logistic Regression Coefficients for Negative Contribution to Bike Purchases')\n",
    "plt.grid(axis='x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter coefficients for positive influence\n",
    "positive_coef_df = coef_df[coef_df['Coefficient'] > 0]\n",
    "\n",
    "# Sort coefficients in descending order\n",
    "positive_coef_df = positive_coef_df.sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "# Plot the coefficients for positive influence\n",
    "plt.figure(figsize=(10, 40))\n",
    "plt.barh(positive_coef_df['Feature'], positive_coef_df['Coefficient'], color='skyblue')\n",
    "plt.xlabel('Coefficient')\n",
    "plt.title('Logistic Regression Coefficients for Positive Influence')\n",
    "plt.grid(axis='x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use RandomForestRegressor when your target variable is a continuous value that you need to predict.\n",
    "- Use RandomForestClassifier when your target variable is a categorical label or class."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uscholar_py3.6_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
