{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, FunctionTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PowerTransformer\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file path\n",
    "file_path=\"C:/Users/Davie/Desktop/introduction-to-power-bi/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load demographic data\n",
    "demographic=pd.read_excel(file_path+\"KPMG/KPMG_VI_New_raw_data_update_final.xlsx\",sheet_name='CustomerDemographic', index_col=False, header=0, usecols=\"A:M\", skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load customer address\n",
    "address=pd.read_excel(file_path+\"KPMG/KPMG_VI_New_raw_data_update_final.xlsx\",sheet_name='CustomerAddress', index_col=False, header=0, usecols=\"A:F\", skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load transaction data\n",
    "transactions=pd.read_excel(file_path+\"KPMG/KPMG_VI_New_raw_data_update_final.xlsx\",sheet_name='Transactions', index_col=False, header=0, usecols=\"A:M\", skiprows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge demographic data with customer address\n",
    "demographic_address=pd.merge(demographic, address, on='customer_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged all the 3 datasets\n",
    "demographic_address_transactions=pd.merge(demographic_address, transactions, on='customer_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicates and ulls\n",
    "df=demographic_address_transactions.drop_duplicates().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make copy of the data\n",
    "data=df.copy().drop_duplicates(subset=['customer_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate product margin\n",
    "data['product_margin']=(data['list_price']-data['standard_cost'])/data['list_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate age\n",
    "\n",
    "# convert DOB to datetime\n",
    "data['DOB']=pd.to_datetime(data['DOB'])\n",
    "# Get the current date\n",
    "current_date = pd.to_datetime('today')\n",
    "# Calculate age using apply and a lambda function to handle the year difference\n",
    "data['age'] = df['DOB'].apply(lambda x: current_date.year - x.year - ((current_date.month, current_date.day) < (x.month, x.day)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define age bins and labels\n",
    "bins = [0, 20, 30, 40, 50, 60, 70, 100]\n",
    "labels = ['<20','20-30','30-40','40-50','50-60','60-70', '>70']\n",
    "\n",
    "# Create age groups\n",
    "data['age_group'] = pd.cut(data['age'], bins=bins, labels=labels, right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date of transaction\n",
    "data['transaction_date'] = pd.to_datetime(data['transaction_date'])\n",
    "\n",
    "# Extract the daya, monthand year from transaction_date\n",
    "data['trans_day'] = data['transaction_date'].dt.day\n",
    "data['trans_month'] = data['transaction_date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace values for gender and state in the entire DataFrame\n",
    "data['gender'] = data['gender'].replace({'Femal': 'Female', 'F': 'Female'})\n",
    "data['state']=data['state'].replace({'New South Wales':'NSW','Victoria':'VIC'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tenure ranges\n",
    "bins = [0, 5, 10, 15, 25]\n",
    "labels = ['<5','5-10', '10-15', '>15']\n",
    "\n",
    "# Create age groups\n",
    "data['tenure_period'] = pd.cut(data['tenure'], bins=bins, labels=labels, right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define proterty valuation ranges\n",
    "bins = [0, 3, 6, 9, 12]\n",
    "labels = ['<3','3-6', '6-9', '>9']\n",
    "\n",
    "# Create age groups\n",
    "data['valuation_category'] = pd.cut(data['property_valuation'], bins=bins, labels=labels, right=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution for Bikes Purchased to be used as the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Frequency'>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#histogram\n",
    "data['past_3_years_bike_related_purchases'].plot.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGdCAYAAAA44ojeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAApGElEQVR4nO3deXxU9b3/8fcEyGQhCQTIJkECRowiO1JwSSwQXLAgVlCwQosWyiIpt6L8cAnyIClcDalQKWAfYSsF73UpoiARBKWghmAQAeEBRIhAGpU0C4REku/vDy7n3mENOnG+gdfz8ZiHnXPOnPnMZGpenjmZcRljjAAAACzi5+sBAAAAzkagAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALBOQ18P8EPU1NToyJEjCgkJkcvl8vU4AACgFowxKisrU0xMjPz8Ln6MpF4GypEjRxQbG+vrMQAAwA9QUFCgli1bXnSbehkoISEhkk4/wNDQUB9PAwAAaqO0tFSxsbHO7/GLqZeBcuZtndDQUAIFAIB6pjanZ3CSLAAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsc9mB8uGHH+q+++5TTEyMXC6X3nrrLY/1xhilpqYqJiZGgYGBSkpK0s6dOz22qays1Pjx49W8eXMFBwfrF7/4hb7++usf9UAAAMCV47ID5fjx4+rYsaPmzJlz3vUzZ85URkaG5syZo5ycHEVFRalv374qKytztklJSdGbb76p5cuXa9OmTSovL1f//v1VXV39wx8JAAC4YriMMeYH39jl0ptvvqmBAwdKOn30JCYmRikpKXrqqacknT5aEhkZqRkzZmjUqFEqKSlRixYttGTJEg0ZMkTS/350/bvvvqt+/fpd8n5LS0sVFhamkpISPqgNAIB64nJ+f3v1HJT8/HwVFhYqOTnZWeZ2u5WYmKjNmzdLknJzc/X99997bBMTE6P27ds725ytsrJSpaWlHhcAAHDl8mqgFBYWSpIiIyM9lkdGRjrrCgsL5e/vr6ZNm15wm7Olp6crLCzMufBFgQAAXNnq5K94zv6MfWPMJT93/2LbTJ48WSUlJc6loKDAa7MCAAD7ePXLAqOioiSdPkoSHR3tLC8qKnKOqkRFRamqqkrFxcUeR1GKiorUq1ev8+7X7XbL7XZ7c1QAXlZRVa3935T/6P2c/L5aXxdXqGXTQAU0auCFyaS2LRor0N87+wLw0/BqoMTFxSkqKkrZ2dnq3LmzJKmqqkobN27UjBkzJEldu3ZVo0aNlJ2drcGDB0uSjh49qi+++EIzZ8705jgAfkL7vylX/9mbfD3Gea0af5vaXxPm6zEAXIbLDpTy8nLt27fPuZ6fn6+8vDyFh4erVatWSklJUVpamuLj4xUfH6+0tDQFBQVp6NChkqSwsDCNHDlS//Ef/6FmzZopPDxcf/jDH3TzzTerT58+3ntkAH5SbVs01qrxt/3o/ewrKlfKijxlDumk6yIae2Gy07MBqF8uO1C2bt2qO++807k+ceJESdLw4cO1cOFCTZo0SRUVFRozZoyKi4vVo0cPrV27ViEhIc5tZs2apYYNG2rw4MGqqKhQ7969tXDhQjVowCFYoL4K9G/g1aMU10U05qgHcBX7UZ+D4it8Dgpw5fricIn6z97E2zLAFchnn4MCAADgDQQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDpeD5RTp07pmWeeUVxcnAIDA9WmTRu98MILqqmpcbYxxig1NVUxMTEKDAxUUlKSdu7c6e1RAABAPeX1QJkxY4b+8pe/aM6cOdq9e7dmzpyp//zP/9Ts2bOdbWbOnKmMjAzNmTNHOTk5ioqKUt++fVVWVubtcQAAQD3k9UDZsmWLBgwYoHvvvVetW7fWL3/5SyUnJ2vr1q2STh89yczM1JQpUzRo0CC1b99eixYt0okTJ7Rs2TJvjwMAAOohrwfKbbfdpnXr1mnv3r2SpO3bt2vTpk265557JEn5+fkqLCxUcnKycxu3263ExERt3rz5vPusrKxUaWmpxwUAAFy5Gnp7h0899ZRKSkp0ww03qEGDBqqurtb06dP18MMPS5IKCwslSZGRkR63i4yM1MGDB8+7z/T0dE2dOtXbowIAAEt5/QjKihUrtHTpUi1btkzbtm3TokWL9OKLL2rRokUe27lcLo/rxphzlp0xefJklZSUOJeCggJvjw0AACzi9SMoTz75pJ5++mk99NBDkqSbb75ZBw8eVHp6uoYPH66oqChJp4+kREdHO7crKio656jKGW63W26329ujAgAAS3n9CMqJEyfk5+e52wYNGjh/ZhwXF6eoqChlZ2c766uqqrRx40b16tXL2+MAAIB6yOtHUO677z5Nnz5drVq10k033aTPPvtMGRkZ+s1vfiPp9Fs7KSkpSktLU3x8vOLj45WWlqagoCANHTrU2+MAAIB6yOuBMnv2bD377LMaM2aMioqKFBMTo1GjRum5555ztpk0aZIqKio0ZswYFRcXq0ePHlq7dq1CQkK8PQ4AAKiHXMYY4+shLldpaanCwsJUUlKi0NBQX48DwIu+OFyi/rM3adX429T+mjBfjwPAiy7n9zffxQMAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsE5DXw8AwLfyvz2u45WnfD2GY19Rucc/bRLsbqi45sG+HgO4KhAowFUs/9vjuvPFDb4e47xSVuT5eoTz+uAPSUQK8BMgUICr2JkjJ5lDOum6iMY+nua0k99X6+viCrVsGqiARg18PY5jX1G5UlbkWXW0CbiSESgAdF1EY7W/JszXYzi6tfb1BAB8jZNkAQCAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdeokUA4fPqxHHnlEzZo1U1BQkDp16qTc3FxnvTFGqampiomJUWBgoJKSkrRz5866GAUAANRDXg+U4uJi3XrrrWrUqJFWr16tXbt26aWXXlKTJk2cbWbOnKmMjAzNmTNHOTk5ioqKUt++fVVWVubtcQAAQD3U0Ns7nDFjhmJjY5WVleUsa926tfO/jTHKzMzUlClTNGjQIEnSokWLFBkZqWXLlmnUqFHeHgkAANQzXj+CsnLlSnXr1k0PPvigIiIi1LlzZy1YsMBZn5+fr8LCQiUnJzvL3G63EhMTtXnz5vPus7KyUqWlpR4XAABw5fJ6oBw4cEBz585VfHy83nvvPY0ePVpPPPGEFi9eLEkqLCyUJEVGRnrcLjIy0ll3tvT0dIWFhTmX2NhYb48NAAAs4vVAqampUZcuXZSWlqbOnTtr1KhRevzxxzV37lyP7Vwul8d1Y8w5y86YPHmySkpKnEtBQYG3xwYAABbxeqBER0frxhtv9FiWkJCgQ4cOSZKioqIk6ZyjJUVFReccVTnD7XYrNDTU4wIAAK5cXg+UW2+9VXv27PFYtnfvXl177bWSpLi4OEVFRSk7O9tZX1VVpY0bN6pXr17eHgcAANRDXv8rnt///vfq1auX0tLSNHjwYH366aeaP3++5s+fL+n0WzspKSlKS0tTfHy84uPjlZaWpqCgIA0dOtTb4wAAgHrI64HSvXt3vfnmm5o8ebJeeOEFxcXFKTMzU8OGDXO2mTRpkioqKjRmzBgVFxerR48eWrt2rUJCQrw9DgAAqIe8HiiS1L9/f/Xv3/+C610ul1JTU5WamloXdw8AAOo5vosHAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYJ2Gvh4AgG+5GpYqv3SP/AIa+3oUq+WXlsvVsNTXYwBXDQIFuMo1avKJ/t+nab4eo15o1KS3pHt8PQZwVSBQgKvc9//uoZfuHaq2ERxBuZj9ReV64m/7fT0GcNUgUICrnDkVqrjQdrqxWZivR7FazckSmVPf+HoM4KrBSbIAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOnUeKOnp6XK5XEpJSXGWGWOUmpqqmJgYBQYGKikpSTt37qzrUQAAQD1Rp4GSk5Oj+fPnq0OHDh7LZ86cqYyMDM2ZM0c5OTmKiopS3759VVZWVpfjAACAeqLOAqW8vFzDhg3TggUL1LRpU2e5MUaZmZmaMmWKBg0apPbt22vRokU6ceKEli1bVlfjAACAeqTOAmXs2LG699571adPH4/l+fn5KiwsVHJysrPM7XYrMTFRmzdvPu++KisrVVpa6nEBAABXroZ1sdPly5dr27ZtysnJOWddYWGhJCkyMtJjeWRkpA4ePHje/aWnp2vq1KneHxQAAFjJ60dQCgoKNGHCBC1dulQBAQEX3M7lcnlcN8acs+yMyZMnq6SkxLkUFBR4dWYAAGAXrx9Byc3NVVFRkbp27eosq66u1ocffqg5c+Zoz549kk4fSYmOjna2KSoqOueoyhlut1tut9vbowIAAEt5/QhK7969tWPHDuXl5TmXbt26adiwYcrLy1ObNm0UFRWl7Oxs5zZVVVXauHGjevXq5e1xAABAPeT1IyghISFq3769x7Lg4GA1a9bMWZ6SkqK0tDTFx8crPj5eaWlpCgoK0tChQ709DgAAqIfq5CTZS5k0aZIqKio0ZswYFRcXq0ePHlq7dq1CQkJ8MQ4AALDMTxIoGzZs8LjucrmUmpqq1NTUn+LuAQBAPcN38QAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOg19PQAA36n4vlqS9MXhEh9P8r9Ofl+tr4sr1LJpoAIaNfD1OI59ReW+HgG4qhAowFVs///80n36jR0+nqT+CHbzr03gp8D/04CrWPJNUZKkthGNFWjJ0Yp9ReVKWZGnzCGddF1EY1+P4yHY3VBxzYN9PQZwVSBQgKtYeLC/Hrqlla/HOK/rIhqr/TVhvh4DgI9wkiwAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACs4/VASU9PV/fu3RUSEqKIiAgNHDhQe/bs8djGGKPU1FTFxMQoMDBQSUlJ2rlzp7dHAQAA9ZTXA2Xjxo0aO3asPv74Y2VnZ+vUqVNKTk7W8ePHnW1mzpypjIwMzZkzRzk5OYqKilLfvn1VVlbm7XEAAEA95PUvC1yzZo3H9aysLEVERCg3N1d33HGHjDHKzMzUlClTNGjQIEnSokWLFBkZqWXLlmnUqFHeHgkAANQzdX4OSklJiSQpPDxckpSfn6/CwkIlJyc727jdbiUmJmrz5s3n3UdlZaVKS0s9LgAA4MpVp4FijNHEiRN12223qX379pKkwsJCSVJkZKTHtpGRkc66s6WnpyssLMy5xMbG1uXYAADAx+o0UMaNG6fPP/9cf//7389Z53K5PK4bY85ZdsbkyZNVUlLiXAoKCupkXgAAYAevn4Nyxvjx47Vy5Up9+OGHatmypbM8KipK0ukjKdHR0c7yoqKic46qnOF2u+V2u+tqVAAAYBmvH0ExxmjcuHF64403tH79esXFxXmsj4uLU1RUlLKzs51lVVVV2rhxo3r16uXtcQAAQD3k9SMoY8eO1bJly/SPf/xDISEhznklYWFhCgwMlMvlUkpKitLS0hQfH6/4+HilpaUpKChIQ4cO9fY4AACgHvJ6oMydO1eSlJSU5LE8KytLI0aMkCRNmjRJFRUVGjNmjIqLi9WjRw+tXbtWISEh3h4HAADUQ14PFGPMJbdxuVxKTU1Vamqqt+8eAABcAfguHgAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdnwbKK6+8ori4OAUEBKhr16766KOPfDkOAACwhM8CZcWKFUpJSdGUKVP02Wef6fbbb9fdd9+tQ4cO+WokAABgCZ8FSkZGhkaOHKnHHntMCQkJyszMVGxsrObOneurkQAAgCUa+uJOq6qqlJubq6efftpjeXJysjZv3nzO9pWVlaqsrHSul5aW1vmMAC5PRVW19n9T/qP3s6+o3OOf3tC2RWMF+jfw2v4A1D2fBMq3336r6upqRUZGeiyPjIxUYWHhOdunp6dr6tSpP9V4AH6A/d+Uq//sTV7bX8qKPK/ta9X429T+mjCv7Q9A3fNJoJzhcrk8rhtjzlkmSZMnT9bEiROd66WlpYqNja3z+QDUXtsWjbVq/G0/ej8nv6/W18UVatk0UAGNvHPUo22Lxl7ZD4Cfjk8CpXnz5mrQoME5R0uKiorOOaoiSW63W263+6caD8APEOjfwGtHKbq19spuANRjPjlJ1t/fX127dlV2drbH8uzsbPXq1csXIwEAAIv47C2eiRMn6le/+pW6deumnj17av78+Tp06JBGjx7tq5EAAIAlfBYoQ4YM0XfffacXXnhBR48eVfv27fXuu+/q2muv9dVIAADAEi5jjPH1EJertLRUYWFhKikpUWhoqK/HAQAAtXA5v7/5Lh4AAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHZ991P2PcebDb0tLS308CQAAqK0zv7dr8yH29TJQysrKJEmxsbE+ngQAAFyusrIyhYWFXXSbevldPDU1NTpy5IhCQkLkcrl8PQ4ALyotLVVsbKwKCgr4ri3gCmOMUVlZmWJiYuTnd/GzTOploAC4cvFloAAkTpIFAAAWIlAAAIB1CBQAVnG73Xr++efldrt9PQoAH+IcFAAAYB2OoAAAAOsQKAAAwDoECgAAsA6BAuAcqamp6tSp00W3GTFihAYOHOhcT0pKUkpKSp3OdbnOnvGn9NVXX8nlcikvL88n919btflZA75AoOCq8kN+abzxxhvq1q2bmjRpouDgYHXq1ElLliypuyHriT/96U9auHChr8fwqvoSFcDVoF5+Fw/wUwoPD9eUKVN0ww03yN/fX6tWrdKvf/1rRUREqF+/fr4e77yqq6vlcrku+VHSP8alvkejLlVVVcnf399n919f8DyhPuMICqyTlJSkcePGady4cWrSpImaNWumZ555xvn2y6VLl6pbt24KCQlRVFSUhg4dqqKiIuf2xcXFGjZsmFq0aKHAwEDFx8crKytLkhQXFydJ6ty5s1wul5KSkmo1z/3336+EhAS1bdtWEyZMUIcOHbRp06ZL3nbx4sVq1qyZKisrPZY/8MADevTRR53rb7/9trp27aqAgAC1adNGU6dO1alTp5z1GRkZuvnmmxUcHKzY2FiNGTNG5eXlzvqFCxeqSZMmWrVqlW688Ua53W4dPHhQGzZs0C233KLg4GA1adJEt956qw4ePHjJuc+YN2+eYmNjFRQUpAcffFD//ve/nXWXevtkzZo1CgsL0+LFiyVJhw8f1pAhQ9S0aVM1a9ZMAwYM0FdffVWrOc7cV3p6umJiYnT99df/oH2uWbNGt912m/O66t+/v/bv3++sv9jrIysrSwkJCQoICNANN9ygV155xWPfn376qTp37qyAgAB169ZNn332Wa0emyRt2LBBLpdL77zzjjp27KiAgAD16NFDO3bscLY531sxmZmZat269SWfp6+//loPPfSQwsPDFRwcrG7duumTTz7x2NeSJUvUunVrhYWF6aGHHnK+lLU2z1tVVZXGjRun6OhoBQQEqHXr1kpPT3fWl5SU6Le//a0iIiIUGhqqn//859q+fbuzfvv27brzzjsVEhKi0NBQde3aVVu3bq3184crE4ECKy1atEgNGzbUJ598opdfflmzZs3Sq6++Kun0vwynTZum7du366233lJ+fr5GjBjh3PbZZ5/Vrl27tHr1au3evVtz585V8+bNJZ3+JSJJ77//vo4ePao33njjsuYyxmjdunXas2eP7rjjjktu/+CDD6q6ulorV650ln377bfOURhJeu+99/TII4/oiSee0K5duzRv3jwtXLhQ06dPd27j5+enl19+WV988YUWLVqk9evXa9KkSR73deLECaWnp+vVV1/Vzp07FR4eroEDByoxMVGff/65tmzZot/+9re1/oLNffv26bXXXtPbb7+tNWvWKC8vT2PHjq3VbZcvX67Bgwdr8eLFevTRR3XixAndeeedaty4sT788ENt2rRJjRs31l133aWqqqpa7XPdunXavXu3srOztWrVqh+0z+PHj2vixInKycnRunXr5Ofnp/vvv181NTWSLvz6WLBggaZMmaLp06dr9+7dSktL07PPPqtFixY5++3fv7/atWun3Nxcpaam6g9/+EOtHtf/9eSTT+rFF19UTk6OIiIi9Itf/ELff//9Ze3j7OepvLxciYmJOnLkiFauXKnt27dr0qRJzmOWpP379+utt97SqlWrtGrVKm3cuFF//OMfa/28vfzyy1q5cqVee+017dmzR0uXLnXCyRije++9V4WFhXr33XeVm5urLl26qHfv3jp27JgkadiwYWrZsqVycnKUm5urp59+Wo0aNbrs5w9XGANYJjEx0SQkJJiamhpn2VNPPWUSEhLOu/2nn35qJJmysjJjjDH33Xef+fWvf33ebfPz840k89lnn13WTP/+979NcHCwadiwoXG73eavf/1rrW/7u9/9ztx9993O9czMTNOmTRvn8d1+++0mLS3N4zZLliwx0dHRF9zna6+9Zpo1a+Zcz8rKMpJMXl6es+y7774zksyGDRtqPesZzz//vGnQoIEpKChwlq1evdr4+fmZo0ePGmOMGT58uBkwYICzPjEx0UyYMMH8+c9/NmFhYWb9+vXOur/+9a+mXbt2Hj/TyspKExgYaN57771LzjN8+HATGRlpKisrL2ufZ894tqKiIiPJ7Nixwxhz4ddHbGysWbZsmceyadOmmZ49expjjJk3b54JDw83x48fd9bPnTu31q+1Dz74wEgyy5cvd5Z99913JjAw0KxYscIYc/pn0rFjR4/bzZo1y1x77bXO9fM9T/PmzTMhISHmu+++O+99P//88yYoKMiUlpY6y5588knTo0ePC8579vM2fvx48/Of/9zjZ3HGunXrTGhoqDl58qTH8rZt25p58+YZY4wJCQkxCxcuvOD94erEOSiw0s9+9jOP/9Lv2bOnXnrpJVVXV+vzzz9Xamqq8vLydOzYMee/4g4dOqQbb7xRv/vd7/TAAw9o27ZtSk5O1sCBA9WrV68fNU9ISIjy8vJUXl6udevWaeLEiWrTpk2t3iJ6/PHH1b17dx0+fFjXXHONsrKyNGLECOfx5ebmKicnx+OISXV1tU6ePKkTJ04oKChIH3zwgdLS0rRr1y6Vlpbq1KlTOnnypI4fP67g4GBJkr+/vzp06ODsIzw8XCNGjFC/fv3Ut29f9enTR4MHD1Z0dHStHnOrVq3UsmVL53rPnj1VU1OjPXv2KCoq6ry3ef311/Wvf/1LmzZt0i233OIsz83N1b59+xQSEuKx/cmTJz3eKriYm2++2eN8ih+yz/379+vZZ5/Vxx9/rG+//dbjtdO+ffvz3uabb75RQUGBRo4cqccff9xZfurUKec8nN27d6tjx44KCgpy1vfs2bNWj+v/+r+3CQ8PV7t27bR79+7L2sfZz1NeXp46d+6s8PDwC96mdevWHs9jdHS0x9uml3reRowYob59+6pdu3a666671L9/fyUnJ0s6/XMqLy9Xs2bNPO6zoqLC+TlNnDhRjz32mJYsWaI+ffrowQcfVNu2bS/rcePKQ6CgXjl58qSSk5OVnJyspUuXqkWLFjp06JD69evnHNa/++67dfDgQb3zzjt6//331bt3b40dO1YvvvjiD75fPz8/XXfddZKkTp06affu3UpPT69VoHTu3FkdO3bU4sWL1a9fP+3YsUNvv/22s76mpkZTp07VoEGDzrltQECADh48qHvuuUejR4/WtGnTFB4erk2bNmnkyJEeh/8DAwPPefsmKytLTzzxhNasWaMVK1bomWeeUXZ2tn72s59d9nNwZt8Xe4uoU6dO2rZtm7KystS9e3dn25qaGnXt2lV/+9vfzrlNixYtanX/Z0LsjB+yz/vuu0+xsbFasGCBYmJiVFNTo/bt21/0baYzv4wXLFigHj16eKxr0KCBJDnnR9WFM8+hn5/fOfdzvrd/zn6eAgMDL3kfZ7+d4nK5PN4CutTz1qVLF+Xn52v16tV6//33NXjwYPXp00f//d//rZqaGkVHR2vDhg3n3G+TJk0knT6/ZujQoXrnnXe0evVqPf/881q+fLnuv//+S86OKxeBAit9/PHH51yPj4/Xl19+qW+//VZ//OMfFRsbK0nnPZmuRYsWGjFihEaMGKHbb7/deW//zH9ZVldX/6j5jDHnnPh6MY899phmzZqlw4cPq0+fPs7s0ul/ue/Zs8cJoLNt3bpVp06d0ksvveT8Vc5rr71W6/vu3LmzOnfurMmTJ6tnz55atmxZrQLl0KFDOnLkiGJiYiRJW7ZskZ+fn3Pi5fm0bdtWL730kpKSktSgQQPNmTPHeYwrVqxwTpL0hsvd53fffafdu3dr3rx5uv322yXpnBOdz/f6iIyM1DXXXKMDBw5o2LBh5933jTfeqCVLlqiiosIJgrNfw7Xx8ccfq1WrVpJOn+y9d+9e3XDDDZJOv6YLCwtljHGipTZ/Dt2hQwe9+uqrOnbs2EWPolxIbZ43SQoNDdWQIUM0ZMgQ/fKXv9Rdd92lY8eOqUuXLiosLFTDhg09Tug92/XXX6/rr79ev//97/Xwww8rKyuLQLnKcZIsrFRQUKCJEydqz549+vvf/67Zs2drwoQJatWqlfz9/TV79mwdOHBAK1eu1LRp0zxu+9xzz+kf//iH9u3bp507d2rVqlVKSEiQJEVERCgwMFBr1qzRv/71L5WUlFxylvT0dGVnZ+vAgQP68ssvlZGRocWLF+uRRx6p9eMZNmyYDh8+rAULFug3v/nNOfMuXrxYqamp2rlzp3bv3u0c7ZBO/9I/deqU85iXLFmiv/zlL5e8z/z8fE2ePFlbtmzRwYMHtXbtWu3du9d5Li4lICBAw4cP1/bt2/XRRx/piSee0ODBgy/49s4Z119/vT744AO9/vrrzge3DRs2TM2bN9eAAQP00UcfKT8/Xxs3btSECRP09ddf12qes13uPs/8pc/8+fO1b98+rV+/XhMnTvTY5kKvj9TUVKWnp+tPf/qT9u7dqx07digrK0sZGRmSpKFDh8rPz08jR47Url279O677/6gI3YvvPCC1q1bpy+++EIjRoxQ8+bNnb+USkpK0jfffKOZM2dq//79+vOf/6zVq1dfcp8PP/ywoqKiNHDgQP3zn//UgQMH9Prrr2vLli21mqk2z9usWbO0fPlyffnll9q7d6/+67/+S1FRUWrSpIn69Omjnj17auDAgXrvvff01VdfafPmzXrmmWe0detWVVRUaNy4cdqwYYMOHjyof/7zn8rJyan16xRXMN+eAgOcKzEx0YwZM8aMHj3ahIaGmqZNm5qnn37aOQFv2bJlpnXr1sbtdpuePXualStXepyMOG3aNJOQkGACAwNNeHi4GTBggDlw4ICz/wULFpjY2Fjj5+dnEhMTLznPlClTzHXXXWcCAgJM06ZNTc+ePT1OZqytX/3qVyY8PPyckwWNMWbNmjWmV69eJjAw0ISGhppbbrnFzJ8/31mfkZFhoqOjTWBgoOnXr59ZvHixkWSKi4uNMadPkg0LC/PYZ2FhoRk4cKCJjo42/v7+5tprrzXPPfecqa6uvuSsZ07IfOWVV0xMTIwJCAgwgwYNMseOHXO2udBJsmfs2rXLREREmIkTJxpjjDl69Kh59NFHTfPmzY3b7TZt2rQxjz/+uCkpKbnkPBc62fVS+zz7dtnZ2SYhIcG43W7ToUMHs2HDBiPJvPnmm842F3p9/O1vfzOdOnUy/v7+pmnTpuaOO+4wb7zxhrN+y5YtpmPHjsbf39906tTJvP7665d9kuzbb79tbrrpJuPv72+6d+/ucdKzMadPvI2NjTXBwcHm0UcfNdOnTz/nJNnzPU9fffWVeeCBB0xoaKgJCgoy3bp1M5988okxpnYn317qeZs/f77p1KmTCQ4ONqGhoaZ3795m27Ztzu1LS0vN+PHjTUxMjGnUqJGJjY01w4YNM4cOHTKVlZXmoYceMrGxscbf39/ExMSYcePGmYqKiks+b7iyuYypwzdPgR8gKSlJnTp1UmZmpq9H8aq+ffsqISFBL7/8sq9HgWU2bNigO++8U8XFxc55GcDVjnNQgDp27NgxrV27VuvXr3fOyQAAXBznoOCq17hx4wtePvroo4ve9tChQxe9/aFDh9SlSxeNGjVKM2bMULt27X6iR3VxN9100wVnPt9fxdS1H/MzqA9Gjx59wcc3evRoX48HWIm3eHDV27dv3wXXXXPNNRf9M81Tp05d9KPVW7durYYN7TtQefDgwQt+QmlkZOQ5ny1S137Mz6A+KCoqUmlp6XnXhYaGKiIi4ieeCLAfgQIAAKzDWzwAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6/x/xRcbSEvaa3IAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#box plot\n",
    "data['past_3_years_bike_related_purchases'].plot.box()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['customer_id', 'first_name', 'last_name', 'gender',\n",
       "       'past_3_years_bike_related_purchases', 'DOB', 'job_title',\n",
       "       'job_industry_category', 'wealth_segment', 'deceased_indicator',\n",
       "       'default', 'owns_car', 'tenure', 'address', 'postcode', 'state',\n",
       "       'country', 'property_valuation', 'transaction_id', 'product_id',\n",
       "       'transaction_date', 'online_order', 'order_status', 'brand',\n",
       "       'product_line', 'product_class', 'product_size', 'list_price',\n",
       "       'standard_cost', 'product_first_sold_date', 'product_margin', 'age',\n",
       "       'age_group', 'trans_day', 'trans_month', 'tenure_period',\n",
       "       'valuation_category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check new columns\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select columns to use in the Model\n",
    "cols=['customer_id', 'gender','age_group', 'state', 'job_industry_category', 'job_title','online_order', 'order_status' ,'wealth_segment',  \n",
    "      'brand','product_line', 'product_class', 'product_size', 'tenure', 'tenure_period', 'past_3_years_bike_related_purchases', \n",
    "      'valuation_category', 'property_valuation', 'product_margin', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select model columns\n",
    "data=data[cols].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding, Setting target and feature variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Choose the encoding method based on the nature of your data and the requirements of your machine learning model. \n",
    "- `One-hot encoding` is suitable when there is no ordinal relationship between categories\n",
    "- `label encoding` is useful when there is an ordinal relationship between categories. \n",
    "- **Example**\n",
    "    - Label encoding for Ordinal Variables\n",
    "    - `ordinal_mapping_prod_size = {'small': 0, 'medium': 1, 'large': 2} #product size`\n",
    "    - `ordinal_data['product_size'] = ordinal_data['product_size'].map(ordinal_mapping_prod_size)`\n",
    "    - `data.reset_index(drop=True, inplace=True)`  # Reset index of X without adding it as a new column\n",
    "    - Select categorical columns `categorical_ordinal = ['product_class', 'product_size']`\n",
    "    - `model_data_class = pd.concat([data_c, encoded_data], axis=1)`\n",
    "    - Initialize LabelEncoder `label_encoder = LabelEncoder()`\n",
    "    - Apply Label Encoding to each column `for col in categorical_ordinal:data_clean[col] = label_encoder.fit_transform(data_clean[col])`\n",
    "- Always remember to handle unknown categories appropriately, especially when using one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make copy of the data\n",
    "classification_model_data=data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating binary variable from continous variable\n",
    "#threshold=classification_model_data['past_3_years_bike_related_purchases'].median()\n",
    "#classification_model_data['purchase_bikes']=(classification_model_data['past_3_years_bike_related_purchases']>threshold).astype(int)\n",
    "\n",
    "classification_model_data['purchase_bikes']=classification_model_data['past_3_years_bike_related_purchases'].apply(lambda x: 1 if x>0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and the target variable\n",
    "features_X = classification_model_data.drop(columns=['purchase_bikes', 'past_3_years_bike_related_purchases', 'customer_id'])\n",
    "target_y = classification_model_data['purchase_bikes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_X, target_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categorical columns and numerical columns\n",
    "categorical_features = ['gender', 'tenure_period','age_group','state', 'job_industry_category','job_title', \n",
    "                    'order_status', 'wealth_segment', 'brand', 'product_line', 'valuation_category', 'product_class', 'product_size']\n",
    "numerical_features = ['product_margin', 'property_valuation', 'tenure'] \n",
    "\n",
    "# Combine preprocessing steps for numerical columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ]) #([], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Pipelines and Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (a) Random Forest\n",
    "- build a model to predict the likelihood of bike purchases based on demographic and product characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.32%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.99      1.00      1.00       440\n",
      "\n",
      "    accuracy                           0.99       443\n",
      "   macro avg       0.50      0.50      0.50       443\n",
      "weighted avg       0.99      0.99      0.99       443\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  0   3]\n",
      " [  0 440]]\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline with RandomForestClassifier\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (b) Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic regression is used for classification tasks, (not regression). \n",
    "- Since we want to determine which demographic and product characteristics influences bike purchases or make customer to purchase the bike, logistic regression is appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9932279909706546\n",
      "Precision: 0.9932279909706546\n",
      "Recall: 1.0\n",
      "F1 Score: 0.9966024915062288\n",
      "ROC AUC Score: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline with LogisticRegression\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000,random_state=42))\n",
    "])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_X, target_y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "print(f'Precision: {precision_score(y_test, y_pred)}')\n",
    "print(f'Recall: {recall_score(y_test, y_pred)}')\n",
    "print(f'F1 Score: {f1_score(y_test, y_pred)}')\n",
    "print(f'ROC AUC Score: {roc_auc_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (c) Decission Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.65%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.99      0.99      0.99       440\n",
      "\n",
      "    accuracy                           0.99       443\n",
      "   macro avg       0.50      0.50      0.50       443\n",
      "weighted avg       0.99      0.99      0.99       443\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  0   3]\n",
      " [  3 437]]\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline with DecisionTreeClassifier\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_X, target_y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (479674055.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[91], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    print('fffff'\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "print('fffff'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LINEAR RGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''# Preprocessing pipeline for numerical data\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "# Preprocessing pipeline for categorical data\n",
    "#categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Combine preprocessing steps for numerical columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features)\n",
    "    ],\n",
    "    remainder='passthrough'  # Keep all other columns as they are (already preprocessed/one-hot encoded)\n",
    ")\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(random_state=42))\n",
    "])\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Visualize feature importances (coefficients)\n",
    "# Get coefficients from the trained model\n",
    "coefficients = model.named_steps['classifier'].coef_[0]\n",
    "\n",
    "# Get feature names (numerical + already one-hot encoded features)\n",
    "feature_names = numerical_features + [col for col in X.columns if col not in numerical_features]\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Coefficient': coefficients})\n",
    "\n",
    "# Filter coefficients for positive influence\n",
    "importance_df = importance_df[importance_df['Coefficient'] > 0]\n",
    "\n",
    "# Sort the DataFrame by absolute value of coefficients\n",
    "importance_df = importance_df.reindex(importance_df.Coefficient.abs().sort_values(ascending=False).index)\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.figure(figsize=(10, 38))\n",
    "plt.barh(importance_df['Feature'], importance_df['Coefficient'])\n",
    "plt.xlabel('Coefficient Value')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importances in Logistic Regression')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Visualize feature importances\n",
    "# Get feature importances from the trained model\n",
    "feature_importances = model.named_steps['classifier'].feature_importances_\n",
    "\n",
    "# Get feature names (numerical + already one-hot encoded features)\n",
    "feature_names = numerical_features + [col for col in X.columns if col not in numerical_features]\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.figure(figsize=(10, 36))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importances in Random Forest Classifier')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DECISSION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Preprocessing pipeline for numerical data\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "# Preprocessing pipeline for categorical data\n",
    "#categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Combine preprocessing steps for numerical columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features)\n",
    "    ],\n",
    "    remainder='passthrough'  # Keep all other columns as they are (already preprocessed/one-hot encoded)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Visualize feature importances\n",
    "# Get feature importances from the trained model\n",
    "feature_importances = model.named_steps['classifier'].feature_importances_\n",
    "\n",
    "# Get feature names (numerical + already one-hot encoded features)\n",
    "feature_names = numerical_features + [col for col in X.columns if col not in numerical_features]\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.figure(figsize=(10, 38))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importances in Decision Tree Classifier')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LOGISTIC REGRESSION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing pipeline for numerical data\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "# Combine preprocessing steps for numerical columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features)\n",
    "    ],\n",
    "    remainder='passthrough'  # Keep all other columns as they already preprocessed/one-hot encoded\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpret the model coefficients\n",
    "\n",
    "# Get the feature names after one-hot encoding and scaling\n",
    "feature_names = numerical_features + [col for col in X.columns if col not in numerical_features]\n",
    "\n",
    "# Get the coefficients from the logistic regression model\n",
    "coefficients = model.named_steps['classifier'].coef_[0]\n",
    "\n",
    "# Create a DataFrame for the coefficients\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': coefficients\n",
    "})\n",
    "\n",
    "# Sort by absolute value of the coefficient to see the most influential features\n",
    "coef_df['Absolute Coefficient'] = coef_df['Coefficient'].abs()\n",
    "coef_df = coef_df.sort_values(by='Absolute Coefficient', ascending=False)\n",
    "\n",
    "#coef_df.to_csv('coj.csv',index=False)\n",
    "\n",
    "print(coef_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter coefficients for negative contribution to bike purchases\n",
    "negative_coef_df = coef_df[coef_df['Coefficient'] < 0]\n",
    "\n",
    "# Sort coefficients in ascending order (from most negative to least negative)\n",
    "negative_coef_df = negative_coef_df.sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "# Plot the coefficients for negative contribution to bike purchases\n",
    "plt.figure(figsize=(10, 36))\n",
    "plt.barh(negative_coef_df['Feature'], negative_coef_df['Coefficient'], color='salmon')\n",
    "plt.xlabel('Coefficient')\n",
    "plt.title('Logistic Regression Coefficients for Negative Contribution to Bike Purchases (Most Negative to Least Negative)')\n",
    "plt.grid(axis='x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter coefficients for positive influence\n",
    "positive_coef_df = coef_df[coef_df['Coefficient'] > 0]\n",
    "\n",
    "# Sort coefficients in descending order\n",
    "positive_coef_df = positive_coef_df.sort_values(by='Coefficient', ascending=True)\n",
    "\n",
    "# Plot the coefficients for positive influence\n",
    "plt.figure(figsize=(10, 36))\n",
    "plt.barh(positive_coef_df['Feature'], positive_coef_df['Coefficient'], color='skyblue')\n",
    "plt.xlabel('Coefficient')\n",
    "plt.title('Logistic Regression Coefficients for Positive Influence')\n",
    "plt.grid(axis='x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make copy\n",
    "reg_data_model=data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numerical and categorical features\n",
    "numerical_features = ['product_margin'] \n",
    "categorical_features = [col for col in reg_data_model.columns if col != 'past_3_years_bike_related_purchases' and col != 'product_margin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant features and the target variable\n",
    "X = reg_data_model.drop(columns=['past_3_years_bike_related_purchases'])\n",
    "y = reg_data_model['past_3_years_bike_related_purchases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "# Preprocessing pipeline for numerical data\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "# Preprocessing pipeline for categorical data\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Combine preprocessing steps for specific columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Define the model pipeline\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'MAE: {mae}')\n",
    "print(f'MSE: {mse}')\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'R-squared: {r2}')\n",
    "\n",
    "# Feature importance\n",
    "# Get the feature names from the preprocessor\n",
    "num_features = preprocessor.transformers_[0][2]\n",
    "cat_features = preprocessor.transformers_[1][1].get_feature_names_out(categorical_features)\n",
    "all_features = num_features + cat_features.tolist()\n",
    "\n",
    "# Get the coefficients\n",
    "coefficients = model.named_steps['regressor'].coef_\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "coef_df = pd.DataFrame({'Feature': all_features, 'Coefficient': coefficients})\n",
    "coef_df = coef_df.sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "# Plot the feature importance\n",
    "plt.figure(figsize=(10, 38))\n",
    "sns.barplot(x='Coefficient', y='Feature', data=coef_df)\n",
    "plt.title('Feature Importance from Linear Regression')\n",
    "plt.xlabel('Coefficient Value')\n",
    "plt.ylabel('Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use RandomForestRegressor when your target variable is a continuous value that you need to predict.\n",
    "- Use RandomForestClassifier when your target variable is a categorical label or class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make copy\n",
    "ran_data_model=data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numerical and categorical features\n",
    "numerical_features = ['product_margin'] \n",
    "categorical_features = [col for col in ran_data_model.columns if col != 'past_3_years_bike_related_purchases' and col != 'product_margin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant features and the target variable\n",
    "X = ran_data_model.drop(columns=['past_3_years_bike_related_purchases'])\n",
    "y = ran_data_model['past_3_years_bike_related_purchases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data: one-hot encode categorical variables and scale numerical variables\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Define the model pipeline\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "r_squared = model.score(X_test, y_test)\n",
    "print(f'R-squared: {r_squared}')\n",
    "\n",
    "# Feature importance\n",
    "# Get the feature names from the preprocessor\n",
    "num_features = preprocessor.transformers_[0][2]\n",
    "cat_features = preprocessor.transformers_[1][1].get_feature_names_out(categorical_features)\n",
    "all_features = num_features + cat_features.tolist()\n",
    "\n",
    "# Get the feature importances\n",
    "importances = model.named_steps['regressor'].feature_importances_\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "importance_df = pd.DataFrame({'Feature': all_features, 'Importance': importances})\n",
    "\n",
    "# Set a threshold for feature importance\n",
    "threshold = 0.001\n",
    "\n",
    "# Filter features based on the threshold\n",
    "important_features_df = importance_df[importance_df['Importance'] >= threshold]\n",
    "\n",
    "# Sort the important features by their importance\n",
    "important_features_df = important_features_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot the feature importance\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=important_features_df)\n",
    "plt.title('Feature Importance from Random Forest')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uscholar_py3.6_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
