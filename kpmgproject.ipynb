{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from datetime import datetime as dt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, FunctionTransformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PowerTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file path\n",
    "file_path=\"C:/Users/Davie/Desktop/introduction-to-power-bi/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load demographic data\n",
    "demographic=pd.read_excel(file_path+\"KPMG/KPMG_VI_New_raw_data_update_final.xlsx\",sheet_name='CustomerDemographic', index_col=False, header=0, usecols=\"A:M\", skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load customer address\n",
    "address=pd.read_excel(file_path+\"KPMG/KPMG_VI_New_raw_data_update_final.xlsx\",sheet_name='CustomerAddress', index_col=False, header=0, usecols=\"A:F\", skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load transaction data\n",
    "transactions=pd.read_excel(file_path+\"KPMG/KPMG_VI_New_raw_data_update_final.xlsx\",sheet_name='Transactions', index_col=False, header=0, usecols=\"A:M\", skiprows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge demographic data with customer address\n",
    "demographic_address=pd.merge(demographic, address, on='customer_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged all the 3 datasets\n",
    "demographic_address_transactions=pd.merge(demographic_address, transactions, on='customer_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicates and ulls\n",
    "df=demographic_address_transactions.drop_duplicates().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make copy of the data\n",
    "data=df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate profit margin\n",
    "data['profit_margin']=data['list_price']-data['standard_cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate product margin\n",
    "data['product_margin']=(data['list_price']-data['standard_cost'])/data['list_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate age\n",
    "\n",
    "# convert DOB to datetime\n",
    "data['DOB']=pd.to_datetime(data['DOB'])\n",
    "# Get the current date\n",
    "current_date = pd.to_datetime('today')\n",
    "# Calculate age using apply and a lambda function to handle the year difference\n",
    "data['age'] = df['DOB'].apply(lambda x: current_date.year - x.year - ((current_date.month, current_date.day) < (x.month, x.day)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define age bins and labels\n",
    "bins = [0, 25, 35, 45, 55, 65, 100]\n",
    "labels = ['0-25','25-35', '35-45', '45-55', '55-65', 'Above 65']\n",
    "\n",
    "# Create age groups\n",
    "data['age_group'] = pd.cut(data['age'], bins=bins, labels=labels, right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date of transaction\n",
    "data['transaction_date'] = pd.to_datetime(data['transaction_date'])\n",
    "\n",
    "# Extract the daya, monthand year from transaction_date\n",
    "data['trans_day'] = data['transaction_date'].dt.day\n",
    "data['trans_month'] = data['transaction_date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace values for gender and state in the entire DataFrame\n",
    "data['gender'] = data['gender'].replace({'Femal': 'Female', 'F': 'Female'})\n",
    "data['state']=data['state'].replace({'New South Wales':'NSW','Victoria':'VIC'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution for Bikes Purchased to be used as the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Frequency'>"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#histogram\n",
    "data['past_3_years_bike_related_purchases'].plot.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#box plot\n",
    "data['past_3_years_bike_related_purchases'].plot.box()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['customer_id', 'first_name', 'last_name', 'gender',\n",
       "       'past_3_years_bike_related_purchases', 'DOB', 'job_title',\n",
       "       'job_industry_category', 'wealth_segment', 'deceased_indicator',\n",
       "       'default', 'owns_car', 'tenure', 'address', 'postcode', 'state',\n",
       "       'country', 'property_valuation', 'transaction_id', 'product_id',\n",
       "       'transaction_date', 'online_order', 'order_status', 'brand',\n",
       "       'product_line', 'product_class', 'product_size', 'list_price',\n",
       "       'standard_cost', 'product_first_sold_date', 'profit_margin',\n",
       "       'product_margin', 'age', 'age_group', 'trans_day', 'trans_month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking new columns\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select columns to use in the Model\n",
    "cols=['gender','age_group', 'state', 'job_industry_category','job_title', 'online_order', 'order_status' ,'wealth_segment',  'brand','product_line', 'product_class', 'product_size', 'tenure', 'past_3_years_bike_related_purchases', 'property_valuation', 'profit_margin', 'product_margin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select model columns\n",
    "data=data[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop nulls\n",
    "data_clean=data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding\n",
    "- Choose the encoding method based on the nature of your data and the requirements of your machine learning model. \n",
    "- `One-hot encoding` is suitable when there is no ordinal relationship between categories\n",
    "- `label encoding` is useful when there is an ordinal relationship between categories. \n",
    "- **Example**\n",
    "    - Label encoding for Ordinal Variables\n",
    "    - `ordinal_mapping_prod_size = {'small': 0, 'medium': 1, 'large': 2} #product size`\n",
    "    - `ordinal_data['product_size'] = ordinal_data['product_size'].map(ordinal_mapping_prod_size)`\n",
    "    - `data.reset_index(drop=True, inplace=True)`  # Reset index of X without adding it as a new column\n",
    "- Always remember to handle unknown categories appropriately, especially when using one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating binary variable from continous variable\n",
    "\n",
    "#create threshold\n",
    "threshold=data_clean['past_3_years_bike_related_purchases'].median()\n",
    "# create high buyers and low buyers\n",
    "data_clean['bikes_purchased']=(data_clean['past_3_years_bike_related_purchases']>threshold).astype(int)\n",
    "#drop past_3_years_bike_related_purchases column\n",
    "data_clean=data_clean.drop(columns=['past_3_years_bike_related_purchases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select categorical columns\n",
    "categorical_ordinal = ['gender', 'age_group', 'product_class', 'product_size']\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Apply Label Encoding to each column\n",
    "for col in categorical_ordinal:\n",
    "    data_clean[col] = label_encoder.fit_transform(data_clean[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age_group</th>\n",
       "      <th>online_order</th>\n",
       "      <th>product_class</th>\n",
       "      <th>product_size</th>\n",
       "      <th>tenure</th>\n",
       "      <th>property_valuation</th>\n",
       "      <th>profit_margin</th>\n",
       "      <th>product_margin</th>\n",
       "      <th>bikes_purchased</th>\n",
       "      <th>...</th>\n",
       "      <th>brand_Giant Bicycles</th>\n",
       "      <th>brand_Norco Bicycles</th>\n",
       "      <th>brand_OHM Cycles</th>\n",
       "      <th>brand_Solex</th>\n",
       "      <th>brand_Trek Bicycles</th>\n",
       "      <th>brand_WeareA2B</th>\n",
       "      <th>product_line_Mountain</th>\n",
       "      <th>product_line_Road</th>\n",
       "      <th>product_line_Standard</th>\n",
       "      <th>product_line_Touring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10</td>\n",
       "      <td>110.56</td>\n",
       "      <td>0.469210</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10</td>\n",
       "      <td>751.02</td>\n",
       "      <td>0.476073</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10</td>\n",
       "      <td>189.28</td>\n",
       "      <td>0.110002</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10</td>\n",
       "      <td>90.10</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10</td>\n",
       "      <td>17.87</td>\n",
       "      <td>0.249965</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12965</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9</td>\n",
       "      <td>114.93</td>\n",
       "      <td>0.200003</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12966</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9</td>\n",
       "      <td>182.81</td>\n",
       "      <td>0.109999</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12967</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5</td>\n",
       "      <td>448.68</td>\n",
       "      <td>0.319686</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12968</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5</td>\n",
       "      <td>143.82</td>\n",
       "      <td>0.250004</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12969</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1055.82</td>\n",
       "      <td>0.598097</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12970 rows  232 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender  age_group  online_order  product_class  product_size  tenure  \\\n",
       "0           0          5           0.0              2             1    11.0   \n",
       "1           0          5           1.0              2             1    11.0   \n",
       "2           0          5           1.0              1             2    11.0   \n",
       "3           0          5           0.0              2             1    11.0   \n",
       "4           0          5           0.0              2             1    11.0   \n",
       "...       ...        ...           ...            ...           ...     ...   \n",
       "12965       1          2           0.0              1             1    19.0   \n",
       "12966       1          2           1.0              0             2    19.0   \n",
       "12967       0          2           1.0              2             1    18.0   \n",
       "12968       0          2           1.0              2             1    18.0   \n",
       "12969       0          2           0.0              2             0    18.0   \n",
       "\n",
       "       property_valuation  profit_margin  product_margin  bikes_purchased  \\\n",
       "0                      10         110.56        0.469210                1   \n",
       "1                      10         751.02        0.476073                1   \n",
       "2                      10         189.28        0.110002                1   \n",
       "3                      10          90.10        0.250000                1   \n",
       "4                      10          17.87        0.249965                1   \n",
       "...                   ...            ...             ...              ...   \n",
       "12965                   9         114.93        0.200003                1   \n",
       "12966                   9         182.81        0.109999                1   \n",
       "12967                   5         448.68        0.319686                1   \n",
       "12968                   5         143.82        0.250004                1   \n",
       "12969                   5        1055.82        0.598097                1   \n",
       "\n",
       "       ...  brand_Giant Bicycles  brand_Norco Bicycles  brand_OHM Cycles  \\\n",
       "0      ...                   0.0                   0.0               1.0   \n",
       "1      ...                   0.0                   0.0               0.0   \n",
       "2      ...                   0.0                   0.0               0.0   \n",
       "3      ...                   0.0                   1.0               0.0   \n",
       "4      ...                   0.0                   0.0               0.0   \n",
       "...    ...                   ...                   ...               ...   \n",
       "12965  ...                   0.0                   0.0               0.0   \n",
       "12966  ...                   0.0                   1.0               0.0   \n",
       "12967  ...                   1.0                   0.0               0.0   \n",
       "12968  ...                   0.0                   0.0               0.0   \n",
       "12969  ...                   1.0                   0.0               0.0   \n",
       "\n",
       "       brand_Solex  brand_Trek Bicycles  brand_WeareA2B  \\\n",
       "0              0.0                  0.0             0.0   \n",
       "1              1.0                  0.0             0.0   \n",
       "2              0.0                  1.0             0.0   \n",
       "3              0.0                  0.0             0.0   \n",
       "4              1.0                  0.0             0.0   \n",
       "...            ...                  ...             ...   \n",
       "12965          0.0                  1.0             0.0   \n",
       "12966          0.0                  0.0             0.0   \n",
       "12967          0.0                  0.0             0.0   \n",
       "12968          1.0                  0.0             0.0   \n",
       "12969          0.0                  0.0             0.0   \n",
       "\n",
       "       product_line_Mountain  product_line_Road  product_line_Standard  \\\n",
       "0                        0.0                0.0                    1.0   \n",
       "1                        0.0                0.0                    1.0   \n",
       "2                        0.0                1.0                    0.0   \n",
       "3                        0.0                0.0                    1.0   \n",
       "4                        0.0                0.0                    1.0   \n",
       "...                      ...                ...                    ...   \n",
       "12965                    1.0                0.0                    0.0   \n",
       "12966                    0.0                0.0                    1.0   \n",
       "12967                    0.0                0.0                    1.0   \n",
       "12968                    0.0                0.0                    1.0   \n",
       "12969                    0.0                0.0                    1.0   \n",
       "\n",
       "       product_line_Touring  \n",
       "0                       0.0  \n",
       "1                       0.0  \n",
       "2                       0.0  \n",
       "3                       0.0  \n",
       "4                       0.0  \n",
       "...                     ...  \n",
       "12965                   0.0  \n",
       "12966                   0.0  \n",
       "12967                   0.0  \n",
       "12968                   0.0  \n",
       "12969                   0.0  \n",
       "\n",
       "[12970 rows x 232 columns]"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select categorical columns\n",
    "categorical_nominal = ['state', 'job_industry_category', 'job_title', \n",
    "                    'order_status', 'wealth_segment', 'brand', 'product_line']\n",
    "\n",
    "# Initialize the OneHotEncoder\n",
    "onehot_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "# Apply the one-hot encoder to the categorical columns\n",
    "encoded_features = onehot_encoder.fit_transform(data_clean[categorical_nominal])\n",
    "\n",
    "# Convert the encoded features into a DataFrame\n",
    "encoded_data = pd.DataFrame(encoded_features, columns=onehot_encoder.get_feature_names_out(categorical_nominal))\n",
    "encoded_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Drop the original categorical columns and concatenate the one-hot encoded columns\n",
    "data = data_clean.drop(categorical_nominal, axis=1)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "model_data = pd.concat([data, encoded_data], axis=1)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "model_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant features and the target variable\n",
    "X = model_data.drop(columns=['bikes_purchased'])\n",
    "y = model_data['bikes_purchased']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Identify categorical and numerical columns\\ncategorical_features = ['gender', 'age_group', 'state', 'job_industry_category', 'job_title', \\n                        'order_status', 'wealth_segment', 'brand', 'product_line', 'product_class', 'product_size']\""
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Identify categorical and numerical columns\n",
    "categorical_features = ['gender', 'age_group', 'state', 'job_industry_category', 'job_title', \n",
    "                        'order_status', 'wealth_segment', 'brand', 'product_line', 'product_class', 'product_size']'''\n",
    "numerical_features = ['product_margin', 'profit_margin', 'property_valuation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM FOREST CLASSIFICATION\n",
    "- NO imbalance in the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing pipeline for numerical data\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "# Combine preprocessing steps for numerical columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features)\n",
    "    ],\n",
    "    remainder='passthrough'  # Keep all other columns as they are (already preprocessed/one-hot encoded)\n",
    ")\n",
    "\n",
    "# Create a pipeline with RandomForestClassifier\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Visualize feature importances\n",
    "# Get feature importances from the trained model\n",
    "feature_importances = model.named_steps['classifier'].feature_importances_\n",
    "\n",
    "# Get feature names (numerical + already one-hot encoded features)\n",
    "feature_names = numerical_features + [col for col in X.columns if col not in numerical_features]\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importances in Random Forest Classifier')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.30%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95      1324\n",
      "           1       0.97      0.94      0.95      1270\n",
      "\n",
      "    accuracy                           0.95      2594\n",
      "   macro avg       0.95      0.95      0.95      2594\n",
      "weighted avg       0.95      0.95      0.95      2594\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1282   42]\n",
      " [  80 1190]]\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the logistic regression model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importances\n",
    "# Get feature importances from the trained model\n",
    "feature_importances = model.named_steps['classifier'].feature_importances_\n",
    "\n",
    "# Get feature names from the preprocessor\n",
    "feature_names = np.hstack([numerical_features, \n",
    "                           model.named_steps['preprocessor']\n",
    "                           .named_transformers_['cat']\n",
    "                           .get_feature_names_out(categorical_features)])\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Visualize feature importances\n",
    "# Get feature importances from the trained model\n",
    "feature_importances = model.named_steps['classifier'].feature_importances_\n",
    "\n",
    "# Get feature names from the preprocessor\n",
    "feature_names = numerical_features + categorical_features\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importances in Random Forest Classifier')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LINEAR RGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing pipeline for numerical data\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "# Preprocessing pipeline for categorical data\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create a pipeline with LinearRegression\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f'Mean Squared Error: {mean_squared_error(y_test, y_pred)}')\n",
    "print(f'R^2 Score: {r2_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DECISSION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing pipeline for numerical data\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "# Preprocessing pipeline for categorical data\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create a pipeline with DecisionTreeRegressor\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', DecisionTreeRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f'Mean Squared Error: {mean_squared_error(y_test, y_pred)}')\n",
    "print(f'R^2 Score: {r2_score(y_test, y_pred)}')\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'regressor__max_depth': [None, 10, 20, 30],\n",
    "    'regressor__min_samples_split': [2, 5, 10],\n",
    "    'regressor__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print('Best parameters:', grid_search.best_params_)\n",
    "print('Best Mean Squared Error:', -grid_search.best_score_)  # Convert back to positive MSE\n",
    "\n",
    "# Use the best estimator for predictions\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Final evaluation of the tuned model\n",
    "print(f'Mean Squared Error (tuned): {mean_squared_error(y_test, y_pred)}')\n",
    "print(f'R^2 Score (tuned): {r2_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: Based on age group, gender, and state, what are the key target demographics for bike purchases?\n",
    "\n",
    "#### Q2: Predictive Modeling:\n",
    "- Can you build a model to predict the likelihood of bike purchases based on demographic and product characteristics?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOGISTIC REGRESSION\n",
    "- Logistic regression is used for classification tasks, not regression. Since you want to predict the likelihood of bike purchases, which is a binary classification problem, logistic regression is indeed appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the target variable to binary if it isn't already\n",
    "y = y.apply(lambda x: 1 if x >0 else 0)  # Assuming bike_purchases &gt; 0 means a purchase\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "'''categorical_features = ['gender', 'age_group', 'state', 'job_industry_category', 'job_title', \n",
    "                        'order_status', 'wealth_segment', 'brand', 'product_line', 'online_order']\n",
    "numerical_features = ['age', 'product_margin', 'profit_margin', 'trans_day', 'trans_month']'''\n",
    "\n",
    "# Preprocessing pipeline for numerical data\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "# Function to pass through categorical data (no transformation needed since already label encoded)\n",
    "categorical_transformer = FunctionTransformer(lambda x: x)\n",
    "'''\n",
    "# Preprocessing pipeline for categorical data\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')'''\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create a pipeline with LogisticRegression\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "print(f'Precision: {precision_score(y_test, y_pred)}')\n",
    "print(f'Recall: {recall_score(y_test, y_pred)}')\n",
    "print(f'F1 Score: {f1_score(y_test, y_pred)}')\n",
    "print(f'ROC AUC Score: {roc_auc_score(y_test, y_pred)}')\n",
    "\n",
    "'''# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'classifier__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'classifier__penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'classifier__solver': ['lbfgs', 'liblinear', 'saga']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='roc_auc')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print('Best parameters:', grid_search.best_params_)\n",
    "print('Best ROC AUC Score:', grid_search.best_score_)\n",
    "\n",
    "# Use the best estimator for predictions\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Final evaluation of the tuned model\n",
    "print(f'Accuracy (tuned): {accuracy_score(y_test, y_pred)}')\n",
    "print(f'Precision (tuned): {precision_score(y_test, y_pred)}')\n",
    "print(f'Recall (tuned): {recall_score(y_test, y_pred)}')\n",
    "print(f'F1 Score (tuned): {f1_score(y_test, y_pred)}')\n",
    "print(f'ROC AUC Score (tuned): {roc_auc_score(y_test, y_pred)}')'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpreting the LOGISTIC CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpret the model coefficients\n",
    "# Get the feature names after one-hot encoding and scaling\n",
    "onehot_columns = model.named_steps['preprocessor'].transformers_[1][1].get_feature_names_out(categorical_features)\n",
    "all_feature_names = np.hstack([numerical_features, onehot_columns])\n",
    "\n",
    "# Get the coefficients from the logistic regression model\n",
    "coefficients = model.named_steps['classifier'].coef_[0]\n",
    "\n",
    "# Create a DataFrame for the coefficients\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': all_feature_names,\n",
    "    'Coefficient': coefficients\n",
    "})\n",
    "\n",
    "# Sort by absolute value of the coefficient to see the most influential features\n",
    "coef_df['Absolute Coefficient'] = coef_df['Coefficient'].abs()\n",
    "coef_df = coef_df.sort_values(by='Absolute Coefficient', ascending=False)\n",
    "\n",
    "print(coef_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter coefficients for negative contribution to bike purchases\n",
    "negative_coef_df = coef_df[coef_df['Coefficient'] < 0]\n",
    "\n",
    "# Sort coefficients in ascending order (from most negative to least negative)\n",
    "negative_coef_df = negative_coef_df.sort_values(by='Coefficient', ascending=True)\n",
    "\n",
    "# Plot the coefficients for negative contribution to bike purchases\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(negative_coef_df['Feature'], negative_coef_df['Coefficient'], color='salmon')\n",
    "plt.xlabel('Coefficient')\n",
    "plt.title('Logistic Regression Coefficients for Negative Contribution to Bike Purchases (Most Negative to Least Negative)')\n",
    "plt.grid(axis='x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter coefficients for positive influence\n",
    "positive_coef_df = coef_df[coef_df['Coefficient'] > 0]\n",
    "\n",
    "# Sort coefficients in descending order\n",
    "positive_coef_df = positive_coef_df.sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "# Plot the coefficients for positive influence\n",
    "plt.figure(figsize=(10, 40))\n",
    "plt.barh(positive_coef_df['Feature'], positive_coef_df['Coefficient'], color='skyblue')\n",
    "plt.xlabel('Coefficient')\n",
    "plt.title('Logistic Regression Coefficients for Positive Influence')\n",
    "plt.grid(axis='x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use RandomForestRegressor when your target variable is a continuous value that you need to predict.\n",
    "- Use RandomForestClassifier when your target variable is a categorical label or class."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uscholar_py3.6_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
