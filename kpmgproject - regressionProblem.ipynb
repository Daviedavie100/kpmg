{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from datetime import datetime as dt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file path\n",
    "file_path=\"C:/Users/Davie/Desktop/introduction-to-power-bi/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load demographic data\n",
    "demographic=pd.read_excel(file_path+\"KPMG/KPMG_VI_New_raw_data_update_final.xlsx\",sheet_name='CustomerDemographic', index_col=False, header=0, usecols=\"A:M\", skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load customer address\n",
    "address=pd.read_excel(file_path+\"KPMG/KPMG_VI_New_raw_data_update_final.xlsx\",sheet_name='CustomerAddress', index_col=False, header=0, usecols=\"A:F\", skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load transaction data\n",
    "transactions=pd.read_excel(file_path+\"KPMG/KPMG_VI_New_raw_data_update_final.xlsx\",sheet_name='Transactions', index_col=False, header=0, usecols=\"A:M\", skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load transaction data\n",
    "new_customers=pd.read_excel(file_path+\"KPMG/KPMG_VI_New_raw_data_update_final.xlsx\",sheet_name='NewCustomerList', index_col=False, header=0, usecols=\"A:P\", skiprows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge demographic data with customer address\n",
    "demographic_address=pd.merge(demographic, address, on='customer_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged all the 3 datasets\n",
    "demographic_address_transactions=pd.merge(demographic_address, transactions, on='customer_id', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop deceased persons\n",
    "df=demographic_address_transactions[demographic_address_transactions['deceased_indicator']=='N']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicated customer ids\n",
    "data=df.dropna(how='any').drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_customers.rename(columns={'past_3_years_bike_related_purchases': 'bikes_purchased'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cus_data=new_customers[new_customers['deceased_indicator']=='N']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Target Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate age\n",
    "\n",
    "# convert DOB to datetime\n",
    "cus_data['DOB']=pd.to_datetime(cus_data['DOB'], errors='coerce')\n",
    "# Get the current date\n",
    "current_date = pd.to_datetime('today')\n",
    "\n",
    "# Now you can safely calculate age\n",
    "cus_data['age'] = cus_data['DOB'].apply(lambda x: current_date.year - x.year - ((current_date.month, current_date.day) < (x.month, x.day)) if pd.notnull(x) else None)\n",
    "\n",
    "#cus_data['age']=cus_data['age'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define age bins and labels\n",
    "bins = [0, 20, 30, 40, 50, 60, 70, 100]\n",
    "labels = ['<20','20-30','30-40','40-50','50-60','60-70', '>70']\n",
    "\n",
    "# Create age groups\n",
    "cus_data['age_group'] = pd.cut(cus_data['age'], bins=bins, labels=labels, right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tenure ranges\n",
    "bins = [0, 5, 10, 15, 25]\n",
    "labels = ['<5','5-10', '10-15', '>15']\n",
    "\n",
    "# Create age groups\n",
    "cus_data['tenure_period'] = pd.cut(cus_data['tenure'], bins=bins, labels=labels, right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define proterty valuation ranges\n",
    "bins = [0, 3, 6, 9, 13]\n",
    "labels = ['<3','3-6', '6-9', '>9']\n",
    "\n",
    "# Create age groups\n",
    "cus_data['valuation_category'] = pd.cut(cus_data['property_valuation'], bins=bins, labels=labels, right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#cus_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cus_data_col=['first_name', 'last_name', 'gender', 'bikes_purchased','DOB', 'age', 'age_group', 'state',\n",
    "       'job_title', 'job_industry_category', 'wealth_segment', 'owns_car', 'tenure', 'tenure_period','property_valuation', 'valuation_category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targeted_new_customers=cus_data[cus_data_col].dropna(how='any').drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targeted_new_customers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate product margin\n",
    "data['product_margin']=(data['list_price']-data['standard_cost'])/data['list_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate age\n",
    "\n",
    "# convert DOB to datetime\n",
    "data['DOB']=pd.to_datetime(data['DOB'], errors='coerce')\n",
    "# Get the current date\n",
    "current_date = pd.to_datetime('today')\n",
    "\n",
    "# Now you can safely calculate age\n",
    "data['age'] = data['DOB'].apply(lambda x: current_date.year - x.year - ((current_date.month, current_date.day) < (x.month, x.day)) if pd.notnull(x) else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define age bins and labels\n",
    "bins = [0, 20, 30, 40, 50, 60, 70, 100]\n",
    "labels = ['<20','20-30','30-40','40-50','50-60','60-70', '>70']\n",
    "\n",
    "# Create age groups\n",
    "data['age_group'] = pd.cut(data['age'], bins=bins, labels=labels, right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date of transaction\n",
    "data['transaction_date'] = pd.to_datetime(data['transaction_date'])\n",
    "\n",
    "# Extract the daya, monthand year from transaction_date\n",
    "data['trans_day'] = data['transaction_date'].dt.day\n",
    "data['trans_month'] = data['transaction_date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace values for gender and state in the entire DataFrame\n",
    "data['gender'] = data['gender'].replace({'Femal': 'Female', 'F': 'Female'})\n",
    "data['state']=data['state'].replace({'New South Wales':'NSW','Victoria':'VIC'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tenure ranges\n",
    "bins = [0, 5, 10, 15, 25]\n",
    "labels = ['<5','5-10', '10-15', '>15']\n",
    "\n",
    "# Create age groups\n",
    "data['tenure_period'] = pd.cut(data['tenure'], bins=bins, labels=labels, right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define proterty valuation ranges\n",
    "bins = [0, 3, 6, 9, 13]\n",
    "labels = ['<3','3-6', '6-9', '>9']\n",
    "\n",
    "# Create age groups\n",
    "data['valuation_category'] = pd.cut(data['property_valuation'], bins=bins, labels=labels, right=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution for Bikes Purchased to be used as the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "data['past_3_years_bike_related_purchases'].plot.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot\n",
    "data['past_3_years_bike_related_purchases'].plot.box()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={'past_3_years_bike_related_purchases':'bikes_purchased'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check new columns\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns to use in the Model\n",
    "'''cols=['customer_id', 'gender','age_group', 'state', 'job_industry_category', 'job_title','online_order', 'order_status' ,'wealth_segment',  \n",
    "      'brand','product_line', 'product_class', 'product_size', 'tenure', 'tenure_period', 'bikes_purchased', \n",
    "      'valuation_category', 'property_valuation', 'product_margin']'''\n",
    "\n",
    "cols=['first_name', 'last_name', 'gender', 'bikes_purchased','DOB', 'age', 'age_group', 'state',\n",
    "       'job_title', 'job_industry_category', 'wealth_segment', 'owns_car', 'tenure', 'tenure_period','property_valuation', 'valuation_category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store cleaned data\n",
    "\n",
    "clean_data=data[cols]\n",
    "#clean_data.to_csv('clean_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the clean dataset\n",
    "\n",
    "#clean_data=pd.read_csv('clean_data.csv')\n",
    "#clean_data.dropna(how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding, Setting target and feature variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Choose the encoding method based on the nature of your data and the requirements of your machine learning model. \n",
    "- `One-hot encoding` is suitable when there is no ordinal relationship between categories\n",
    "- `label encoding` is useful when there is an ordinal relationship between categories. \n",
    "- **Example**\n",
    "    - Label encoding for Ordinal Variables\n",
    "    - `ordinal_mapping_prod_size = {'small': 0, 'medium': 1, 'large': 2} #product size`\n",
    "    - `ordinal_data['product_size'] = ordinal_data['product_size'].map(ordinal_mapping_prod_size)`\n",
    "    - `data.reset_index(drop=True, inplace=True)`  # Reset index of X without adding it as a new column\n",
    "    - Select categorical columns `categorical_ordinal = ['product_class', 'product_size']`\n",
    "    - `model_data_class = pd.concat([data_c, encoded_data], axis=1)`\n",
    "    - Initialize LabelEncoder `label_encoder = LabelEncoder()`\n",
    "    - Apply Label Encoding to each column `for col in categorical_ordinal:data_clean[col] = label_encoder.fit_transform(data_clean[col])`\n",
    "- Always remember to handle unknown categories appropriately, especially when using one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make copy of the data\n",
    "regression_model_data=clean_data.copy()\n",
    "#regression_model_data.reset_index(drop=True, inplace=True)\n",
    "regression_model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make copy of the data\n",
    "regression_target_data=targeted_new_customers.copy()\n",
    "#regression_model_data.reset_index(drop=True, inplace=True)\n",
    "regression_target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to detertime customer demographic and product characteristics that influences bike purchase and identify \n",
    "# and target customers based on their demographic attributes\n",
    "# So since only less tha 1% of the customer did not buy bikes, it makes this a regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categorical columns and numerical columns\n",
    "'''categorical_features = ['gender', 'age_group','state', 'job_industry_category','job_title', \n",
    "                     'wealth_segment', 'brand', 'product_line', \n",
    "                     'product_class', 'product_size', 'tenure_period', 'valuation_category', 'order_status']''' \n",
    "\n",
    "categorical_features=['gender', 'bikes_purchased','age_group', 'state',\n",
    "       'job_title', 'job_industry_category', 'wealth_segment', 'owns_car', 'tenure_period', 'valuation_category']\n",
    "\n",
    "numerical_features = ['age', 'property_valuation', 'tenure'] \n",
    "\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoders = {col: LabelEncoder() for col in categorical_features}\n",
    "\n",
    "# Encode the regression model data columns\n",
    "for col in categorical_features:\n",
    "    regression_model_data[col] = label_encoders[col].fit_transform(regression_model_data[col])\n",
    "\n",
    "regression_model_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Encode the targeted new customer data columns\n",
    "for col in categorical_features:\n",
    "    regression_target_data[col] = label_encoders[col].fit_transform(regression_target_data[col])\n",
    "\n",
    "regression_target_data.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categorical columns and numerical columns\n",
    "'''categorical_features = ['gender', 'age_group','state', 'job_industry_category','job_title', \n",
    "                     'wealth_segment', 'brand', 'product_line', \n",
    "                     'product_class', 'product_size', 'tenure_period', 'valuation_category', 'order_status'] \n",
    "\n",
    "numerical_features = ['product_margin', 'property_valuation', 'tenure' ] \n",
    "\n",
    "# Preprocessing pipeline for numerical data\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "# Preprocessing pipeline for categorical data\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Combine preprocessing steps for specific columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])'''\n",
    "\n",
    "\n",
    "# Preprocessing pipeline for numerical data\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "# Combine preprocessing steps for numerical columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features)\n",
    "    ],\n",
    "    remainder='passthrough'  # Keep all other columns as they are (already preprocessed/one-hot encoded)\n",
    ")\n",
    "\n",
    "\n",
    "# Create a pipeline with LogisticRegression\n",
    "model_ran = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Define and the target variable\n",
    "features_X = regression_model_data.drop(columns=['bikes_purchased','first_name', 'last_name','DOB' ]) #'valuation_category', 'tenure_period',\n",
    "target_y = regression_model_data['bikes_purchased']\n",
    "\n",
    "# Adjust the columns as necessary\n",
    "X_new_customers = regression_target_data[features_X.columns]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_X, target_y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model_ran.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model_ran.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae=mean_absolute_error(y_test,y_pred)\n",
    "mse=mean_squared_error(y_test, y_pred)\n",
    "rmse=mse*0.5\n",
    "r2 = r2_score(y_test, y_pred) #r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "print(f'Mean Absolute Error (MAE): {mae}')\n",
    "print(f'Mean Squared Error (MSE): {mse}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
    "print(f'R_squraed (R_Squared): {r2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Pipelines and Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (a) Random Forest\n",
    "- build a model to predict the likelihood of bike purchases based on demographic and product characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the new target customer dataset\n",
    "new_customer_predictions = model_ran.predict(X_new_customers)\n",
    "\n",
    "# Define a threshold for selecting customers\n",
    "threshold = 40  # Example threshold, adjust based on your business needs\n",
    "\n",
    "# Select customers whose predicted values exceed the threshold\n",
    "selected_customers = targeted_new_customers[new_customer_predictions > threshold]\n",
    "\n",
    "# Attach predictions to the selected customer DataFrame\n",
    "selected_customers = selected_customers.copy()  # Avoid SettingWithCopyWarning\n",
    "selected_customers['predicted_value'] = new_customer_predictions[new_customer_predictions > threshold]\n",
    "\n",
    "# Sort customers by their predicted probabilities\n",
    "target_customers=selected_customers.sort_values(by='predicted_value', ascending=False)\n",
    "\n",
    "# Save the selected customers to a CSV file (optional)\n",
    "target_customers.to_csv('selected_customers.csv', index=False)\n",
    "\n",
    "# Load selected customers data\n",
    "targeted_customers=pd.read_csv('selected_customers.csv')\n",
    "\n",
    "'''# predict on the whole dataset\n",
    "targeted_new_customers['predicted_bikes_purchased']=model_ran.predict(features_X)\n",
    "\n",
    "# Set threshold for the targeted customers\n",
    "threshold=90\n",
    "\n",
    "# Identify customers to the target\n",
    "target_customers=targeted_new_customers[targeted_new_customers['predicted_bikes_purchased']>threshold]\n",
    "\n",
    "# Sort customers by their predicted probabilities\n",
    "target_customers=target_customers.sort_values(by='predicted_bikes_purchased', ascending=False)\n",
    "target_customers.reset_index(drop=True, inplace=True)\n",
    "target_customers[['predicted_bikes_purchased', 'state', 'gender', 'age_group']]#.drop_duplicates(subset='customer_id') #['customer_id', 'predicted_bikes_purchased', 'state', 'gender', 'age_group']'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targeted_customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (b) Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic regression is used for classification tasks, (not regression). \n",
    "- Since we want to determine which demographic and product characteristics influences bike purchases or make customer to purchase the bike, logistic regression is appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model pipeline\n",
    "model_lin = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_X, target_y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model_lin.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model_lin.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'MAE: {mae}')\n",
    "print(f'MSE: {mse}')\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'R-squared: {r2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Predict prob for the whole data including training and testing sets\n",
    "predicted_probabilities=model_log.predict_proba(features_X)[:,1]\n",
    "\n",
    "# Add predicted prob to the original dataset\n",
    "data['predicted_probabilities']=predicted_probabilities\n",
    "\n",
    "# Set threshold for the targeted customers\n",
    "threshold=0.9\n",
    "\n",
    "# Identify customers to the target\n",
    "target_customers=data[data['predicted_probabilities']>threshold]\n",
    "\n",
    "# Sort customers by their predicted probabilities\n",
    "target_customers=target_customers.sort_values(by='customer_id', ascending=True)\n",
    "\n",
    "target_customers[['customer_id', 'predicted_probabilities', 'gender', 'tenure_period','age_group','state', 'job_industry_category','job_title', \n",
    "                    'order_status', 'wealth_segment', 'brand', 'product_line', 'valuation_category', 'product_class', 'product_size', 'product_margin']]'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (c) Decission Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline with DecisionTreeClassifier\n",
    "model_det = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', DecisionTreeRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_X, target_y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model_det.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model_det.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae=mean_absolute_error(y_test,y_pred)\n",
    "mse=mean_squared_error(y_test, y_pred)\n",
    "rmse=mse*0.5\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Absolute Error (MAE): {mae}')\n",
    "print(f'Mean Squared Error (MSE): {mse}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
    "print(f'R_squraed (R_Squared): {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DECISSION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Preprocessing pipeline for numerical data\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "# Preprocessing pipeline for categorical data\n",
    "#categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Combine preprocessing steps for numerical columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features)\n",
    "    ],\n",
    "    remainder='passthrough'  # Keep all other columns as they are (already preprocessed/one-hot encoded)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Visualize feature importances\n",
    "# Get feature importances from the trained model\n",
    "feature_importances = model.named_steps['classifier'].feature_importances_\n",
    "\n",
    "# Get feature names (numerical + already one-hot encoded features)\n",
    "feature_names = numerical_features + [col for col in X.columns if col not in numerical_features]\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.figure(figsize=(10, 38))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importances in Decision Tree Classifier')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LOGISTIC REGRESSION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Interpret the model coefficients\n",
    "\n",
    "# Get the feature names after one-hot encoding and scaling\n",
    "feature_names = numerical_features + [col for col in X.columns if col not in numerical_features]\n",
    "\n",
    "# Get the coefficients from the logistic regression model\n",
    "coefficients = model.named_steps['classifier'].coef_[0]\n",
    "\n",
    "# Create a DataFrame for the coefficients\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': coefficients\n",
    "})\n",
    "\n",
    "# Sort by absolute value of the coefficient to see the most influential features\n",
    "coef_df['Absolute Coefficient'] = coef_df['Coefficient'].abs()\n",
    "coef_df = coef_df.sort_values(by='Absolute Coefficient', ascending=False)\n",
    "\n",
    "#coef_df.to_csv('coj.csv',index=False)\n",
    "\n",
    "print(coef_df)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Filter coefficients for negative contribution to bike purchases\n",
    "negative_coef_df = coef_df[coef_df['Coefficient'] < 0]\n",
    "\n",
    "# Sort coefficients in ascending order (from most negative to least negative)\n",
    "negative_coef_df = negative_coef_df.sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "# Plot the coefficients for negative contribution to bike purchases\n",
    "plt.figure(figsize=(10, 36))\n",
    "plt.barh(negative_coef_df['Feature'], negative_coef_df['Coefficient'], color='salmon')\n",
    "plt.xlabel('Coefficient')\n",
    "plt.title('Logistic Regression Coefficients for Negative Contribution to Bike Purchases (Most Negative to Least Negative)')\n",
    "plt.grid(axis='x')\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Filter coefficients for positive influence\n",
    "positive_coef_df = coef_df[coef_df['Coefficient'] > 0]\n",
    "\n",
    "# Sort coefficients in descending order\n",
    "positive_coef_df = positive_coef_df.sort_values(by='Coefficient', ascending=True)\n",
    "\n",
    "# Plot the coefficients for positive influence\n",
    "plt.figure(figsize=(10, 36))\n",
    "plt.barh(positive_coef_df['Feature'], positive_coef_df['Coefficient'], color='skyblue')\n",
    "plt.xlabel('Coefficient')\n",
    "plt.title('Logistic Regression Coefficients for Positive Influence')\n",
    "plt.grid(axis='x')\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make copy\n",
    "reg_data_model=clean_data.copy()\n",
    "reg_data_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numerical and categorical features\n",
    "numerical_features = ['product_margin'] # 'property_valuation', 'tenure'\n",
    "categorical_features = ['customer_id','gender','age_group','state','job_industry_category','job_title','online_order','order_status','wealth_segment','brand','product_line','product_class','product_size','tenure_period','valuation_category']\n",
    "\n",
    "'''[col for col in reg_data_model.columns if col != 'past_3_years_bike_related_purchases' \n",
    "                        and col != 'product_margin'\n",
    "                        and col !='tenure'\n",
    "                        and col !='property_valuation']'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant features and the target variable\n",
    "X = reg_data_model.drop(columns=['past_3_years_bike_related_purchases',  'property_valuation', 'tenure'])\n",
    "y = reg_data_model['past_3_years_bike_related_purchases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "# Preprocessing pipeline for numerical data\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "# Preprocessing pipeline for categorical data\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Combine preprocessing steps for specific columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Define the model pipeline\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'MAE: {mae}')\n",
    "print(f'MSE: {mse}')\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'R-squared: {r2}')\n",
    "\n",
    "# Feature importance\n",
    "# Get the feature names from the preprocessor\n",
    "num_features = preprocessor.transformers_[0][2]\n",
    "cat_features = preprocessor.transformers_[1][1].get_feature_names_out(categorical_features)\n",
    "all_features = num_features + cat_features.tolist()\n",
    "\n",
    "# Get the coefficients\n",
    "coefficients = model.named_steps['regressor'].coef_\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "coef_df = pd.DataFrame({'Feature': all_features, 'Coefficient': coefficients})\n",
    "coef_df = coef_df.sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "# Plot the feature importance\n",
    "plt.figure(figsize=(10, 38))\n",
    "sns.barplot(x='Coefficient', y='Feature', data=coef_df)\n",
    "plt.title('Feature Importance from Linear Regression')\n",
    "plt.xlabel('Coefficient Value')\n",
    "plt.ylabel('Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use RandomForestRegressor when your target variable is a continuous value that you need to predict.\n",
    "- Use RandomForestClassifier when your target variable is a categorical label or class."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uscholar_py3.6_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
